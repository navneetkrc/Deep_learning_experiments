{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Q+wSiDkajfML2/5mEiVw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Deep_learning_experiments/blob/master/NER_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Both NER and Classification"
      ],
      "metadata": {
        "id": "MMECAXQoBF4S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7CePYdT_7dj"
      },
      "outputs": [],
      "source": [
        "# == CELL 1: Install Dependencies and Set Up ngrok ==\n",
        "# Run this cell FIRST.\n",
        "\n",
        "!pip install streamlit gliner gliclass transformers torch pyngrok nest_asyncio\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "from pyngrok import ngrok, conf\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio (required for Colab)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def get_free_port():\n",
        "    \"\"\"Finds a free port.\"\"\"\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind(('', 0))\n",
        "        return s.getsockname()[1]\n",
        "\n",
        "def run_streamlit(port):\n",
        "    \"\"\"Starts Streamlit in a separate process.\"\"\"\n",
        "    print(f\"Starting Streamlit on port {port}...\")\n",
        "    cmd = [\n",
        "        \"streamlit\", \"run\", \"temp_app.py\",\n",
        "        \"--server.port\", str(port),\n",
        "        \"--server.headless\", \"true\",\n",
        "        \"--browser.serverAddress\", \"localhost\"\n",
        "    ]\n",
        "    subprocess.Popen(cmd)\n",
        "\n",
        "def start_ngrok(port):\n",
        "    \"\"\"Starts ngrok and returns the URL.\"\"\"\n",
        "    from google.colab import userdata\n",
        "    ngrok_token = userdata.get('NGROK_TOKEN')\n",
        "\n",
        "    conf.get_default().auth_token = ngrok_token\n",
        "    conf.get_default().region = 'us'\n",
        "    os.system(\"killall ngrok\")  # Kill existing processes\n",
        "\n",
        "    print(f\"Starting ngrok tunnel for port {port}...\")\n",
        "    tunnel = ngrok.connect(port)\n",
        "    print(\"Ngrok tunnel:\", tunnel.public_url)\n",
        "    return tunnel.public_url"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == CELL 2: Define and Run Streamlit App (ALL-IN-ONE) ==\n",
        "# Run this cell SECOND.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    free_port = get_free_port()\n",
        "\n",
        "    # ALL Streamlit app code, including imports, goes into this string:\n",
        "    streamlit_app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from gliner import GLiNER\n",
        "from gliclass import GLiClassModel, ZeroShotClassificationPipeline\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "from pyngrok import ngrok, conf  #Although not used, kept if future modification is required\n",
        "import os\n",
        "import nest_asyncio  #Although not used, kept if future modification is required\n",
        "\n",
        "# Apply nest_asyncio (required for Colab) #Although not used, kept if future modification is required\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Determine available device\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load GLiNER models (cached)\n",
        "@st.cache_resource\n",
        "def load_gliner_model(model_name):\n",
        "    return GLiNER.from_pretrained(model_name)\n",
        "\n",
        "# Load GLiClass models (cached)\n",
        "@st.cache_resource\n",
        "def load_gliclass_model(model_name):\n",
        "    model = GLiClassModel.from_pretrained(model_name)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    pipeline = ZeroShotClassificationPipeline(model, tokenizer, classification_type='multi-label', device=device)\n",
        "    return pipeline\n",
        "\n",
        "# Available models\n",
        "GLINER_MODELS = {\n",
        "    \"knowledgator/modern-gliner-bi-large-v1.0\": \"GLiNER BiLarge v1.0\",\n",
        "    \"knowledgator/gliner-multitask-large-v0.5\": \"GLiNER multi task\",\n",
        "    \"knowledgator/modern-gliner-bi-base-v1.0\": \"GLiNER Base\"\n",
        "}\n",
        "\n",
        "GLICLASS_MODELS = {\n",
        "    \"knowledgator/gliclass-modern-base-v2.0-init\": \"GLiClass Modern Base v2.0\",\n",
        "    \"knowledgator/gliclass-modern-large-v2.0-init\": \"GLiClass Modern Large v2.0\"\n",
        "}\n",
        "\n",
        "\n",
        "# --- Streamlit App Code (defined as a function) ---\n",
        "def streamlit_app():  # The Streamlit app logic\n",
        "    st.set_page_config(page_title=\"Text Analysis with GLiNER & GLiClass\", layout=\"wide\")\n",
        "    st.title(\"Text Analysis with GLiNER & GLiClass\")\n",
        "    st.markdown(\"Compare entity extraction and zero-shot classification across multiple models\")\n",
        "\n",
        "    if 'default_gliner' not in st.session_state:\n",
        "        st.session_state.default_gliner = list(GLINER_MODELS.keys())[0]\n",
        "    if 'default_gliclass' not in st.session_state:\n",
        "        st.session_state.default_gliclass = list(GLICLASS_MODELS.keys())[0]\n",
        "    if 'analysis_type' not in st.session_state:\n",
        "        st.session_state.analysis_type = \"NER\"\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.header(\"Settings\")\n",
        "        st.session_state.analysis_type = st.radio(\n",
        "            \"Analysis Type\",\n",
        "            [\"Named Entity Recognition (NER)\", \"Zero-Shot Classification\"],\n",
        "            index=0,\n",
        "            format_func=lambda x: x.split(\" \")[0] if \"(\" in x else x\n",
        "        )\n",
        "        is_ner = \"Named\" in st.session_state.analysis_type\n",
        "        st.subheader(\"Model Selection\")\n",
        "\n",
        "        if is_ner:\n",
        "            st.session_state.default_gliner = st.selectbox(\n",
        "                \"Set default NER model:\",\n",
        "                options=list(GLINER_MODELS.keys()),\n",
        "                format_func=lambda x: GLINER_MODELS[x],\n",
        "                index=list(GLINER_MODELS.keys()).index(st.session_state.default_gliner)\n",
        "            )\n",
        "            selected_models = [st.session_state.default_gliner]\n",
        "            remaining_models = [m for m in GLINER_MODELS.keys() if m != st.session_state.default_gliner]\n",
        "            for i, model in enumerate(remaining_models[:2]):\n",
        "                if st.checkbox(f\"Also use {GLINER_MODELS[model]}\", key=f\"gliner_{i}\"):\n",
        "                    selected_models.append(model)\n",
        "        else:\n",
        "            st.session_state.default_gliclass = st.selectbox(\n",
        "                \"Set default classification model:\",\n",
        "                options=list(GLICLASS_MODELS.keys()),\n",
        "                format_func=lambda x: GLICLASS_MODELS[x],\n",
        "                index=list(GLICLASS_MODELS.keys()).index(st.session_state.default_gliclass)\n",
        "            )\n",
        "            selected_models = [st.session_state.default_gliclass]\n",
        "            remaining_models = [m for m in GLICLASS_MODELS.keys() if m != st.session_state.default_gliclass]\n",
        "            for i, model in enumerate(remaining_models[:2]):\n",
        "                if st.checkbox(f\"Also use {GLICLASS_MODELS[model]}\", key=f\"gliclass_{i}\"):\n",
        "                    selected_models.append(model)\n",
        "\n",
        "        threshold = st.slider(\"Confidence Threshold\", min_value=0.1, max_value=0.9, value=0.5, step=0.05)\n",
        "        st.divider()\n",
        "        st.markdown(\"### About\")\n",
        "        st.markdown(\"This app uses GLiNER for named entity recognition and GLiClass for zero-shot classification.\")\n",
        "\n",
        "    st.subheader(\"Text Input\")\n",
        "    example_text = \"One day I will see the world!\"\n",
        "\n",
        "    text = st.text_area(\n",
        "        \"Enter text for analysis:\",\n",
        "        value=example_text,\n",
        "        height=150,\n",
        "        placeholder=\"Enter your text here...\"\n",
        "    )\n",
        "\n",
        "    default_ner_labels = [\"product\", \"product type\", \"price\", \"memory\", \"feature\"]\n",
        "    default_class_labels = [\"product\", \"product type\", \"price\", \"memory\", \"feature\"]\n",
        "\n",
        "    if is_ner:\n",
        "        st.subheader(\"Entity Labels\")\n",
        "        default_labels = default_ner_labels\n",
        "    else:\n",
        "        st.subheader(\"Classification Labels\")\n",
        "        default_labels = default_class_labels\n",
        "\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "    selected_labels = {}\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"**Default Labels:**\")\n",
        "        for label in default_labels:\n",
        "            selected_labels[label] = st.checkbox(label, value=True)\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"**Add Custom Labels:**\")\n",
        "        custom_label = st.text_input(\"New label:\", placeholder=\"Enter a custom label\")\n",
        "        if custom_label and st.button(\"Add Label\"):\n",
        "            if custom_label.lower() not in [l.lower() for l in selected_labels.keys()]:\n",
        "                selected_labels[custom_label] = True\n",
        "                st.success(f\"Added '{custom_label}' to labels\")\n",
        "            else:\n",
        "                st.warning(\"This label already exists\")\n",
        "\n",
        "    final_labels = [label for label, selected in selected_labels.items() if selected]\n",
        "    st.markdown(\"### Selected Labels:\")\n",
        "    st.write(\", \".join(final_labels) if final_labels else \"No labels selected\")\n",
        "\n",
        "    if st.button(\"Analyze Text\"):\n",
        "        if not text.strip():\n",
        "            st.error(\"Please provide text for analysis.\")\n",
        "        elif not final_labels:\n",
        "            st.error(\"Please select at least one label.\")\n",
        "        else:\n",
        "            model_names = [GLINER_MODELS[model] if is_ner else GLICLASS_MODELS[model] for model in selected_models]\n",
        "            tabs = st.tabs(model_names)\n",
        "            colors = {}\n",
        "            default_colors = [\"#FF9AA2\", \"#FFB7B2\", \"#FFDAC1\", \"#E2F0CB\", \"#B5EAD7\", \"#C7CEEA\"]\n",
        "            model_cache = {}\n",
        "\n",
        "            for i, model_name in enumerate(selected_models):\n",
        "                with tabs[i]:\n",
        "                    with st.spinner(f\"Analyzing with {model_names[i]}...\"):\n",
        "                        if is_ner:\n",
        "                            if model_name not in model_cache:\n",
        "                                model_cache[model_name] = load_gliner_model(model_name)\n",
        "                            model = model_cache[model_name]\n",
        "                            entities = model.predict_entities(text, final_labels, threshold=threshold)\n",
        "                            for entity in entities:\n",
        "                                if entity['label'] not in colors:\n",
        "                                    colors[entity['label']] = default_colors[len(colors) % len(default_colors)]\n",
        "\n",
        "                            if entities:\n",
        "                                entities_html = text\n",
        "                                for entity in sorted(entities, key=lambda e: e.get('score', 0), reverse=True):\n",
        "                                    if entity['text'] in entities_html:\n",
        "                                        highlight = f'<span style=\"background-color: {colors[entity[\"label\"]]}; padding: 2px; border-radius: 3px;\">{entity[\"text\"]} <small>({entity[\"label\"]} - {entity.get(\"score\", 0):.2f})</small></span>'\n",
        "                                        entities_html = entities_html.replace(entity['text'], highlight, 1)\n",
        "                                st.write(\"Text with highlighted entities:\")\n",
        "                                st.markdown(entities_html, unsafe_allow_html=True)\n",
        "                                st.markdown(\"### Entity List:\")\n",
        "                                entity_data = {\"Entity\": [], \"Label\": [], \"Confidence\": []}\n",
        "                                for entity in entities:\n",
        "                                    entity_data[\"Entity\"].append(entity['text'])\n",
        "                                    entity_data[\"Label\"].append(entity['label'])\n",
        "                                    entity_data[\"Confidence\"].append(f\"{entity.get('score', 0):.2f}\")\n",
        "                                st.table(entity_data)\n",
        "                                st.markdown(\"### Entity Statistics:\")\n",
        "                                label_counts = {}\n",
        "                                for entity in entities:\n",
        "                                    label = entity['label']\n",
        "                                    if label in label_counts:\n",
        "                                        label_counts[label] += 1\n",
        "                                    else:\n",
        "                                        label_counts[label] = 1\n",
        "                                st.bar_chart(label_counts)\n",
        "                            else:\n",
        "                                st.info(\"No entities matching your labels were found in the text.\")\n",
        "                        else:\n",
        "                            if model_name not in model_cache:\n",
        "                                model_cache[model_name] = load_gliclass_model(model_name)\n",
        "                            pipeline = model_cache[model_name]\n",
        "                            results = pipeline(text, final_labels, threshold=threshold)[0]\n",
        "                            if results:\n",
        "                                st.markdown(\"### Classification Results:\")\n",
        "                                label_data = {}\n",
        "                                for result in results:\n",
        "                                    label = result[\"label\"]\n",
        "                                    score = result[\"score\"]\n",
        "                                    label_data[label] = score\n",
        "                                    if label not in colors:\n",
        "                                        colors[label] = default_colors[len(colors) % len(default_colors)]\n",
        "                                st.bar_chart(label_data)\n",
        "                                class_data = {\"Label\": [], \"Confidence\": []}\n",
        "                                for result in sorted(results, key=lambda x: x[\"score\"], reverse=True):\n",
        "                                    class_data[\"Label\"].append(result[\"label\"])\n",
        "                                    class_data[\"Confidence\"].append(f\"{result['score']:.4f}\")\n",
        "                                st.table(class_data)\n",
        "                                st.markdown(\"### Text with predicted labels:\")\n",
        "                                classes_html = f'<div style=\"padding: 10px; border: 1px solid #ccc; border-radius: 5px;\">{text}<br><br><b>Predicted labels:</b> '\n",
        "                                for result in sorted(results, key=lambda x: x[\"score\"], reverse=True):\n",
        "                                    label = result[\"label\"]\n",
        "                                    score = result[\"score\"]\n",
        "                                    classes_html += f'<span style=\"background-color: {colors[label]}; padding: 2px 6px; margin: 0 4px; border-radius: 3px;\">{label} ({score:.2f})</span>'\n",
        "                                classes_html += '</div>'\n",
        "                                st.markdown(classes_html, unsafe_allow_html=True)\n",
        "                            else:\n",
        "                                st.info(\"No labels crossed the confidence threshold.\")\n",
        "\n",
        "    if 'colors' in locals() and colors:\n",
        "        st.sidebar.markdown(\"### Color Legend:\")\n",
        "        for label, color in colors.items():\n",
        "            st.sidebar.markdown(\n",
        "                f'<div style=\"background-color: {color}; padding: 5px; border-radius: 3px; margin-bottom: 5px;\">{label}</div>',\n",
        "                unsafe_allow_html=True\n",
        "            )\n",
        "\n",
        "streamlit_app()  # Calling the function to run the app\n",
        "\"\"\"\n",
        "\n",
        "    # Write the ENTIRE app code to temp_app.py\n",
        "    with open(\"temp_app.py\", \"w\") as f:\n",
        "        f.write(streamlit_app_code)\n",
        "\n",
        "    # Run Streamlit in a separate thread\n",
        "    thread = threading.Thread(target=run_streamlit, args=(free_port,))\n",
        "    thread.start()\n",
        "    time.sleep(5)  # Wait for Streamlit\n",
        "\n",
        "    public_url = start_ngrok(free_port)  # Get the ngrok URL\n",
        "    print(f\"Access your Streamlit app at: {public_url}\")\n",
        "\n",
        "    while True:  # Keep the notebook alive\n",
        "        time.sleep(60)"
      ],
      "metadata": {
        "id": "JlsFAi38AAFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tHCIlWEuA77j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZxYfTpRgA7td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPvJOBNcA7rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24-r_s1HA8vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Only NER"
      ],
      "metadata": {
        "id": "1bfdvvoZA9Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# == CELL 1: Install Dependencies and Set Up ngrok ==\n",
        "# Run this cell FIRST.\n",
        "\n",
        "!pip install streamlit gliner transformers torch pyngrok nest_asyncio\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "from pyngrok import ngrok, conf\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "# Apply nest_asyncio (required for Colab)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def get_free_port():\n",
        "    \"\"\"Finds a free port.\"\"\"\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.bind(('', 0))\n",
        "        return s.getsockname()[1]\n",
        "\n",
        "def run_streamlit(port):\n",
        "    \"\"\"Starts Streamlit in a separate process.\"\"\"\n",
        "    print(f\"Starting Streamlit on port {port}...\")\n",
        "    cmd = [\n",
        "        \"streamlit\", \"run\", \"temp_app.py\",\n",
        "        \"--server.port\", str(port),\n",
        "        \"--server.headless\", \"true\",\n",
        "        \"--browser.serverAddress\", \"localhost\"\n",
        "    ]\n",
        "    subprocess.Popen(cmd)\n",
        "\n",
        "def start_ngrok(port):\n",
        "    \"\"\"Starts ngrok and returns the URL.\"\"\"\n",
        "    from google.colab import userdata\n",
        "    ngrok_token = userdata.get('NGROK_TOKEN')\n",
        "\n",
        "    conf.get_default().auth_token = ngrok_token\n",
        "    conf.get_default().region = 'us'\n",
        "    os.system(\"killall ngrok\")  # Kill existing processes\n",
        "\n",
        "    print(f\"Starting ngrok tunnel for port {port}...\")\n",
        "    tunnel = ngrok.connect(port)\n",
        "    print(\"Ngrok tunnel:\", tunnel.public_url)\n",
        "    return tunnel.public_url"
      ],
      "metadata": {
        "id": "l-WIZ7TjBBMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# == CELL 2: Define and Run Streamlit App (NER ONLY) ==\n",
        "# Run this cell SECOND.\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    free_port = get_free_port()\n",
        "\n",
        "    # ALL Streamlit app code (NER only), including imports, goes into this string:\n",
        "    streamlit_app_code = \"\"\"\n",
        "import streamlit as st\n",
        "from gliner import GLiNER\n",
        "from transformers import AutoTokenizer  # We only need AutoTokenizer for GLiNER\n",
        "import torch\n",
        "\n",
        "# Determine available device\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load GLiNER models (cached)\n",
        "@st.cache_resource\n",
        "def load_gliner_model(model_name):\n",
        "    return GLiNER.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Available GLiNER models\n",
        "GLINER_MODELS = {\n",
        "    \"knowledgator/modern-gliner-bi-large-v1.0\": \"GLiNER BiLarge v1.0\",\n",
        "    \"knowledgator/gliner-multitask-large-v0.5\": \"GLiNER multi task\",\n",
        "    \"knowledgator/modern-gliner-bi-base-v1.0\": \"GLiNER Base\"\n",
        "}\n",
        "\n",
        "\n",
        "# --- Streamlit App Code (NER Only) ---\n",
        "def streamlit_app():\n",
        "    st.set_page_config(page_title=\"Text Analysis with GLiNER\", layout=\"wide\")  # Updated title\n",
        "    st.title(\"Named Entity Recognition with GLiNER\")  # Updated title\n",
        "    st.markdown(\"Extract named entities from text using GLiNER.\") # Updated description\n",
        "\n",
        "    if 'default_gliner' not in st.session_state:\n",
        "        st.session_state.default_gliner = list(GLINER_MODELS.keys())[0]\n",
        "\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.header(\"Settings\")\n",
        "        st.subheader(\"Model Selection\")\n",
        "\n",
        "        # GLiNER models\n",
        "        st.session_state.default_gliner = st.selectbox(\n",
        "            \"Select NER model:\",  # Simplified label\n",
        "            options=list(GLINER_MODELS.keys()),\n",
        "            format_func=lambda x: GLINER_MODELS[x],\n",
        "            index=list(GLINER_MODELS.keys()).index(st.session_state.default_gliner)\n",
        "        )\n",
        "\n",
        "        # Multiple model selection (up to 3)\n",
        "        selected_models = []\n",
        "        selected_models.append(st.session_state.default_gliner)  # Default model always selected\n",
        "\n",
        "        # Add options for additional models\n",
        "        remaining_models = [m for m in GLINER_MODELS.keys() if m != st.session_state.default_gliner]\n",
        "        for i, model in enumerate(remaining_models[:2]):  # Limit to 2 additional models\n",
        "            if st.checkbox(f\"Also use {GLINER_MODELS[model]}\", key=f\"gliner_{i}\"):\n",
        "                selected_models.append(model)\n",
        "\n",
        "\n",
        "        threshold = st.slider(\"Confidence Threshold\", min_value=0.1, max_value=0.9, value=0.5, step=0.05)\n",
        "        st.divider()\n",
        "        st.markdown(\"### About\")\n",
        "        st.markdown(\"This app uses GLiNER for named entity recognition.\")\n",
        "\n",
        "    st.subheader(\"Text Input\")\n",
        "    example_text = \"What is the difference between the Samsung Galaxy S23 and S23 Ultra?, What does 'Dynamic AMOLED 2X' mean in a Samsung display?, How do I use the S Pen on my Samsung Galaxy Note or Ultra phone?, What is 'One UI' on Samsung phones?, What is 'Samsung Knox' and why is it important?, What is the difference between Samsung QLED and Neo QLED TVs?, What is 'SmartThings' in Samsung appliances?, What is 'Bespoke' in Samsung refrigerators?, What does 'EcoBubble' mean in Samsung washing machines?, What is the Samsung Galaxy Watch and what are its features?, What are Samsung's different memory and storage devices?, What is the difference between a Samsung soundbar and a home theater system?\"\n",
        "\n",
        "    text = st.text_area(\n",
        "        \"Enter text for analysis:\",\n",
        "        value=example_text,\n",
        "        height=150,\n",
        "        placeholder=\"Enter your text here...\"\n",
        "    )\n",
        "\n",
        "    default_ner_labels = [\"product\", \"product type\", \"price\", \"memory\", \"feature\"]\n",
        "    st.subheader(\"Entity Labels\")\n",
        "    default_labels = default_ner_labels\n",
        "\n",
        "\n",
        "    col1, col2 = st.columns([1, 1])\n",
        "    selected_labels = {}\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\"**Default Labels:**\")\n",
        "        for label in default_labels:\n",
        "            selected_labels[label] = st.checkbox(label, value=True)\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\"**Add Custom Labels:**\")\n",
        "        custom_label = st.text_input(\"New label:\", placeholder=\"Enter a custom label\")\n",
        "        if custom_label and st.button(\"Add Label\"):\n",
        "            if custom_label.lower() not in [l.lower() for l in selected_labels.keys()]:\n",
        "                selected_labels[custom_label] = True\n",
        "                st.success(f\"Added '{custom_label}' to labels\")\n",
        "            else:\n",
        "                st.warning(\"This label already exists\")\n",
        "\n",
        "    final_labels = [label for label, selected in selected_labels.items() if selected]\n",
        "    st.markdown(\"### Selected Labels:\")\n",
        "    st.write(\", \".join(final_labels) if final_labels else \"No labels selected\")\n",
        "\n",
        "    if st.button(\"Analyze Text\"):\n",
        "        if not text.strip():\n",
        "            st.error(\"Please provide text for analysis.\")\n",
        "        elif not final_labels:\n",
        "            st.error(\"Please select at least one label.\")\n",
        "        else:\n",
        "            model_names = [GLINER_MODELS[model] for model in selected_models]\n",
        "            tabs = st.tabs(model_names)\n",
        "            colors = {}\n",
        "            default_colors = [\"#FF9AA2\", \"#FFB7B2\", \"#FFDAC1\", \"#E2F0CB\", \"#B5EAD7\", \"#C7CEEA\"]\n",
        "            model_cache = {}\n",
        "\n",
        "            for i, model_name in enumerate(selected_models):\n",
        "                with tabs[i]:\n",
        "                    with st.spinner(f\"Analyzing with {model_names[i]}...\"):\n",
        "                        if model_name not in model_cache:\n",
        "                            model_cache[model_name] = load_gliner_model(model_name)\n",
        "                        model = model_cache[model_name]\n",
        "                        entities = model.predict_entities(text, final_labels, threshold=threshold)\n",
        "                        for entity in entities:\n",
        "                            if entity['label'] not in colors:\n",
        "                                colors[entity['label']] = default_colors[len(colors) % len(default_colors)]\n",
        "\n",
        "                        if entities:\n",
        "                            entities_html = text\n",
        "                            for entity in sorted(entities, key=lambda e: e.get('score', 0), reverse=True):\n",
        "                                if entity['text'] in entities_html:\n",
        "                                    highlight = f'<span style=\"background-color: {colors[entity[\"label\"]]}; padding: 2px; border-radius: 3px;\">{entity[\"text\"]} <small>({entity[\"label\"]} - {entity.get(\"score\", 0):.2f})</small></span>'\n",
        "                                    entities_html = entities_html.replace(entity['text'], highlight, 1)\n",
        "                            st.write(\"Text with highlighted entities:\")\n",
        "                            st.markdown(entities_html, unsafe_allow_html=True)\n",
        "                            st.markdown(\"### Entity List:\")\n",
        "                            entity_data = {\"Entity\": [], \"Label\": [], \"Confidence\": []}\n",
        "                            for entity in entities:\n",
        "                                entity_data[\"Entity\"].append(entity['text'])\n",
        "                                entity_data[\"Label\"].append(entity['label'])\n",
        "                                entity_data[\"Confidence\"].append(f\"{entity.get('score', 0):.2f}\")\n",
        "                            st.table(entity_data)\n",
        "                            st.markdown(\"### Entity Statistics:\")\n",
        "                            label_counts = {}\n",
        "                            for entity in entities:\n",
        "                                label = entity['label']\n",
        "                                if label in label_counts:\n",
        "                                    label_counts[label] += 1\n",
        "                                else:\n",
        "                                    label_counts[label] = 1\n",
        "                            st.bar_chart(label_counts)\n",
        "                        else:\n",
        "                            st.info(\"No entities matching your labels were found in the text.\")\n",
        "\n",
        "\n",
        "    if 'colors' in locals() and colors:\n",
        "        st.sidebar.markdown(\"### Color Legend:\")\n",
        "        for label, color in colors.items():\n",
        "            st.sidebar.markdown(\n",
        "                f'<div style=\"background-color: {color}; padding: 5px; border-radius: 3px; margin-bottom: 5px;\">{label}</div>',\n",
        "                unsafe_allow_html=True\n",
        "            )\n",
        "\n",
        "streamlit_app()  # Calling the function to run the app\n",
        "\"\"\"\n",
        "\n",
        "    # Write the ENTIRE app code to temp_app.py\n",
        "    with open(\"temp_app.py\", \"w\") as f:\n",
        "        f.write(streamlit_app_code)\n",
        "\n",
        "    # Run Streamlit in a separate thread\n",
        "    thread = threading.Thread(target=run_streamlit, args=(free_port,))\n",
        "    thread.start()\n",
        "    time.sleep(5)  # Wait for Streamlit\n",
        "\n",
        "    public_url = start_ngrok(free_port)  # Get the ngrok URL\n",
        "    print(f\"Access your Streamlit app at: {public_url}\")\n",
        "\n",
        "    while True:  # Keep the notebook alive\n",
        "        time.sleep(60)"
      ],
      "metadata": {
        "id": "lP8cIdMKA7n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKO9_C8DA7lJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}