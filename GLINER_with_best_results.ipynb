{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpMIdHZzpnQlYqgbbCzPKF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b280744a83d463ea1c07f8494c70cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_235d3b5c34f84c17b3a47c7764991c18",
              "IPY_MODEL_d4b2dd9d62284d88ab61684d8ba081e9",
              "IPY_MODEL_94c9424f0bb1454896db0490ddd12895"
            ],
            "layout": "IPY_MODEL_daf3de86bf7f4c45a9b96aa97feacc94"
          }
        },
        "235d3b5c34f84c17b3a47c7764991c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ce842071754cfb87ad38b0bf1eb8f7",
            "placeholder": "​",
            "style": "IPY_MODEL_eb7fe436b17b484281d5792f5f2416f1",
            "value": "Fetching 9 files: 100%"
          }
        },
        "d4b2dd9d62284d88ab61684d8ba081e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89f421dd1cd849bcac24148a94f6991f",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce962f25ae7d49eea4a40505145c912a",
            "value": 9
          }
        },
        "94c9424f0bb1454896db0490ddd12895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a191b51e635b42c8b8952cd6f1421612",
            "placeholder": "​",
            "style": "IPY_MODEL_54c13c6f95854737b303f9bd4bdf37c3",
            "value": " 9/9 [00:00&lt;00:00, 389.60it/s]"
          }
        },
        "daf3de86bf7f4c45a9b96aa97feacc94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ce842071754cfb87ad38b0bf1eb8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb7fe436b17b484281d5792f5f2416f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89f421dd1cd849bcac24148a94f6991f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce962f25ae7d49eea4a40505145c912a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a191b51e635b42c8b8952cd6f1421612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c13c6f95854737b303f9bd4bdf37c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cbae6f13ed243eeb5e76ddb5af150de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e31cb77e3043410c8ee33b08256dc3e3",
              "IPY_MODEL_73ab4243bfcc45cc9698606b6fa84155",
              "IPY_MODEL_3166ca97af91476eb1b8a294e76fc9d6"
            ],
            "layout": "IPY_MODEL_5d9d4ce03c664c26863c378447ff784b"
          }
        },
        "e31cb77e3043410c8ee33b08256dc3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25567e29767549ba81de8928738ce788",
            "placeholder": "​",
            "style": "IPY_MODEL_41b568ab56354d8a943badc4039ce4d9",
            "value": "Fetching 9 files: 100%"
          }
        },
        "73ab4243bfcc45cc9698606b6fa84155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_006ed44dbb514d0d88afd7df6a8eae12",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0acc9bf2722942a49fae5590fc5ceda1",
            "value": 9
          }
        },
        "3166ca97af91476eb1b8a294e76fc9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1561392e9b71492c8b4358ea53e72432",
            "placeholder": "​",
            "style": "IPY_MODEL_603f3ef46df74ce6a88c984a2ba41679",
            "value": " 9/9 [00:00&lt;00:00, 508.12it/s]"
          }
        },
        "5d9d4ce03c664c26863c378447ff784b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25567e29767549ba81de8928738ce788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b568ab56354d8a943badc4039ce4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "006ed44dbb514d0d88afd7df6a8eae12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0acc9bf2722942a49fae5590fc5ceda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1561392e9b71492c8b4358ea53e72432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603f3ef46df74ce6a88c984a2ba41679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Deep_learning_experiments/blob/master/GLINER_with_best_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AFcG1gtECPpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio gliner pyngrok transformers streamlit pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ6i8njsCPDv",
        "outputId": "54a638a7-7776-4d2f-ee85-c10b0316f77e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
            "Requirement already satisfied: gliner in /usr/local/lib/python3.11/dist-packages (0.2.16)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.43.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gliner) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gliner) (4.67.1)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (from gliner) (1.20.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from gliner) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.28.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->gliner) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->gliner) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->gliner) (25.2.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime->gliner) (10.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading streamlit-1.43.0-py2.py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.43.0 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gliner import GLiNER\n",
        "\n",
        "model = GLiNER.from_pretrained(\"knowledgator/gliner-multitask-v1.0\")\n",
        "\n",
        "text = \"\"\"\n",
        "Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975 to develop and sell BASIC interpreters for the Altair 8800. During his career at Microsoft, Gates held the positions of chairman, chief executive officer, president and chief software architect, while also being the largest individual shareholder until May 2014.\n",
        "\"\"\"\n",
        "\n",
        "labels = [\"founder\", \"computer\", \"software\", \"position\", \"date\"]\n",
        "\n",
        "entities = model.predict_entities(text, labels)\n",
        "\n",
        "for entity in entities:\n",
        "    print(entity[\"text\"], \"=>\", entity[\"label\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "9b280744a83d463ea1c07f8494c70cc7",
            "235d3b5c34f84c17b3a47c7764991c18",
            "d4b2dd9d62284d88ab61684d8ba081e9",
            "94c9424f0bb1454896db0490ddd12895",
            "daf3de86bf7f4c45a9b96aa97feacc94",
            "16ce842071754cfb87ad38b0bf1eb8f7",
            "eb7fe436b17b484281d5792f5f2416f1",
            "89f421dd1cd849bcac24148a94f6991f",
            "ce962f25ae7d49eea4a40505145c912a",
            "a191b51e635b42c8b8952cd6f1421612",
            "54c13c6f95854737b303f9bd4bdf37c3"
          ]
        },
        "id": "M-eow7eNCPOZ",
        "outputId": "68dff1c3-9ddd-48de-97a9-910439388d88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b280744a83d463ea1c07f8494c70cc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bill Gates => founder\n",
            "Paul Allen => founder\n",
            "April 4, 1975 => date\n",
            "BASIC interpreters => software\n",
            "Altair 8800 => computer\n",
            "chairman => position\n",
            "chief executive officer => position\n",
            "president => position\n",
            "chief software architect => position\n",
            "May 2014 => date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975 to develop and sell BASIC interpreters for the Altair 8800. During his career at Microsoft, Gates held the positions of chairman, chief executive officer, president and chief software architect, while also being the largest individual shareholder until May 2014.\n",
        "\"\"\"\n",
        "\n",
        "labels = [\"Microsoft <> founder\", \"Microsoft <> inception date\", \"Bill Gates <> held position\"]\n",
        "\n",
        "entities = model.predict_entities(text, labels)\n",
        "\n",
        "for entity in entities:\n",
        "    print(entity[\"label\"], \"=>\", entity[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWVwoCSXCPLi",
        "outputId": "d305aa1c-2977-454f-f425-f8a610d67533"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft <> founder => Bill Gates\n",
            "Microsoft <> founder => Paul Allen\n",
            "Microsoft <> inception date => April 4, 1975\n",
            "Bill Gates <> held position => chairman\n",
            "Bill Gates <> held position => chief executive officer\n",
            "Bill Gates <> held position => president\n",
            "Bill Gates <> held position => chief software architect\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('NGROK_AUTH_TOKEN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pZT2sS8KCPI8",
        "outputId": "0ca06170-b3d2-4653-e622-72b497b5c8eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2qRLX76ycIV3fRoWMCCmimd2OME_2AFxAeCBpmzskB9L5ZZhs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Union\n",
        "from gliner import GLiNER\n",
        "import gradio as gr\n",
        "import torch  # Import torch\n",
        "from pyngrok import ngrok  # Import ngrok\n",
        "import os\n",
        "\n",
        "# Use CUDA if available, otherwise use CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = GLiNER.from_pretrained(\"knowledgator/gliner-multitask-v1.0\").to(device)\n",
        "\n",
        "text1 = \"\"\"\n",
        "\"I recently purchased the Sony WH-1000XM4 Wireless Noise-Canceling Headphones from Amazon and I must say, I'm thoroughly impressed. The package arrived in New York within 2 days, thanks to Amazon Prime's expedited shipping.\n",
        "\n",
        "The headphones themselves are remarkable. The noise-canceling feature works like a charm in the bustling city environment, and the 30-hour battery life means I don't have to charge them every day. Connecting them to my Samsung Galaxy S21 was a breeze, and the sound quality is second to none.\n",
        "\n",
        "I also appreciated the customer service from Amazon when I had a question about the warranty. They responded within an hour and provided all the information I needed.\n",
        "\n",
        "However, the headphones did not come with a hard case, which was listed in the product description. I contacted Amazon, and they offered a 10% discount on my next purchase as an apology.\n",
        "\n",
        "Overall, I'd give these headphones a 4.5/5 rating and highly recommend them to anyone looking for top-notch quality in both product and service.\"\"\"\n",
        "\n",
        "\n",
        "text3 = \"\"\"\n",
        "Several studies have reported its pharmacological activities, including anti-inflammatory, antimicrobial, and antitumoral effects.\n",
        "The effect of E-anethole was studied in the osteosarcoma MG-63 cell line, and the antiproliferative activity was evaluated by an MTT assay.\n",
        "It showed a GI50 value of 60.25 μM with apoptosis induction through the mitochondrial-mediated pathway. Additionally, it induced cell cycle arrest at the G0/G1 phase, up-regulated the expression of p53, caspase-3, and caspase-9, and down-regulated Bcl-xL expression.\n",
        "Moreover, the antitumoral activity of anethole was assessed against oral tumor Ca9-22 cells, and the cytotoxic effects were evaluated by MTT and LDH assays.\n",
        "It demonstrated a LD50 value of 8 μM, and cellular proliferation was 42.7% and 5.2% at anethole concentrations of 3 μM and 30 μM, respectively.\n",
        "It was reported that it could selectively and in a dose-dependent manner decrease cell proliferation and induce apoptosis, as well as induce autophagy, decrease ROS production, and increase glutathione activity. The cytotoxic effect was mediated through NF-kB, MAP kinases, Wnt, caspase-3 and -9, and PARP1 pathways. Additionally, treatment with anethole inhibited cyclin D1 oncogene expression, increased cyclin-dependent kinase inhibitor p21WAF1, up-regulated p53 expression, and inhibited the EMT markers.\n",
        "\"\"\"\n",
        "\n",
        "text5 = \"\"\"\n",
        "Dr. Paul Hammond, a renowned neurologist at Johns Hopkins University, has recently published a paper in the prestigious journal \"Nature Neuroscience\". His research focuses on a rare genetic mutation, found in less than 0.01% of the population, that appears to prevent the development of Alzheimer's disease. Collaborating with researchers at the University of California, San Francisco, the team is now working to understand the mechanism by which this mutation confers its protective effect. Funded by the National Institutes of Health, their research could potentially open new avenues for Alzheimer's treatment.\n",
        "\"\"\"\n",
        "\n",
        "ner_examples = [\n",
        "\n",
        "    [\n",
        "        text5,\n",
        "        \"neurologist, scientist, gene, disease, biological process, city, journal, university\",\n",
        "        0.4,\n",
        "        True\n",
        "    ],\n",
        "    [\n",
        "        text1,\n",
        "        \"product, brand, location, features, rating\",\n",
        "        0.5,\n",
        "        False\n",
        "    ],\n",
        "    [\n",
        "        text3,\n",
        "        \"cell line, protein, metric, substance\",\n",
        "        0.5,\n",
        "        False\n",
        "    ],\n",
        "    [\n",
        "        \"\"\"\n",
        "* Data Scientist, Data Analyst, or Data Engineer with 1+ years of experience.\n",
        "* Experience with technologies such as Docker, Kubernetes, or Kubeflow\n",
        "* Machine Learning experience preferred\n",
        "* Experience with programming languages such as Python, C++, or SQL preferred\n",
        "* Experience with technologies such as Databricks, Qlik, TensorFlow, PyTorch, Python, Dash, Pandas, or NumPy preferred\n",
        "* BA or BS degree\n",
        "* Active Secret OR Active Top Secret or Active TS/SCI clearance\n",
        "\"\"\",\n",
        "        \"software package, programing language, software tool, degree, job title\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"However, both models lack other frequent DM symptoms including the fibre-type dependent atrophy, myotonia, cataract and male-infertility.\",\n",
        "        \"disease, symptom\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"Synergy between signal transduction pathways is obligatory for expression of c-fos in B and T cell lines: implication for c-fos control via surface immunoglobulin and T cell antigen receptors.\",\n",
        "        \"DNA, RNA, cell line, cell type, protein\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"The choice of the encoder and decoder modules of dnpg can be quite flexible, for instance long short term memory networks (lstm) or convolutional neural network (cnn).\",\n",
        "        \"short acronym, long acronym\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"Amelia Earhart flew her single engine Lockheed Vega 5B across the Atlantic to Paris.\",\n",
        "        \"person, company, location, airplane\",\n",
        "        0.3,\n",
        "        True,\n",
        "    ],\n",
        "    [\n",
        "        \"Feldman is a contributor to NBC Sports Boston's ``State of the Revs`` and ``Revolution Postgame Live`` programs as well as to 98.5 the SportsHub, SiriusXM FC's MLS coverage and to other New England and national radio outlets and podcasts.\",\n",
        "        \"person, company, location\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"On 25 July 1948, on the 39th anniversary of Bleriot's crossing of the English Channel, the Type 618 Nene-Viking flew Heathrow to Paris (Villacoublay) in the morning carrying letters to Bleriot's widow and son (secretary of the FAI), who met it at the airport.\",\n",
        "        \"date, location, person, organization\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"Leo & Ian won the 1962 Bathurst Six Hour Classic at Mount Panorama driving a Daimler SP250 sports car, (that year the 500 mile race for touring cars were held at Phillip Island)\",\n",
        "        \"person, date, location, organization, competition\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"The Shore Line route of the CNS & M until 1955 served, from south to north, the Illinois communities of Chicago, Evanston, Wilmette, Kenilworth, Winnetka, Glencoe, Highland Park, Highwood, Fort Sheridan, Lake Forest, Lake Bluff, North Chicago, Waukegan, Zion, and Winthrop Harbor as well as Kenosha, Racine, and Milwaukee (the ``KRM'') in Wisconsin.\",\n",
        "        \"location, organization, date\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ],\n",
        "    [\n",
        "        \"Comet C/2006 M4 (SWAN) is a non-periodic comet discovered in late June 2006 by Robert D. Matson of Irvine, California and Michael Mattiazzo of Adelaide, South Australia in publicly available images of the Solar and Heliospheric Observatory (SOHO).\",\n",
        "        \"person, organization, date, location\",\n",
        "        0.3,\n",
        "        False,\n",
        "    ]]\n",
        "\n",
        "def merge_entities(entities):\n",
        "    if not entities:\n",
        "        return []\n",
        "    merged = []\n",
        "    current = entities[0]\n",
        "    for next_entity in entities[1:]:\n",
        "        if next_entity['entity'] == current['entity'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
        "            current['word'] += ' ' + next_entity['word']\n",
        "            current['end'] = next_entity['end']\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = next_entity\n",
        "    merged.append(current)\n",
        "    return merged\n",
        "\n",
        "def process(\n",
        "    text, labels: str, threshold: float, nested_ner: bool\n",
        ") -> Dict[str, Union[str, int, float]]:\n",
        "    labels = [label.strip() for label in labels.split(\",\")]\n",
        "    r = {\n",
        "        \"text\": text,\n",
        "        \"entities\": [\n",
        "            {\n",
        "                \"entity\": entity[\"label\"],\n",
        "                \"word\": entity[\"text\"],\n",
        "                \"start\": entity[\"start\"],\n",
        "                \"end\": entity[\"end\"],\n",
        "                \"score\": 0,\n",
        "            }\n",
        "            for entity in model.predict_entities(\n",
        "                text, labels, flat_ner=not nested_ner, threshold=threshold\n",
        "            )\n",
        "        ],\n",
        "    }\n",
        "    r[\"entities\"] =  merge_entities(r[\"entities\"])\n",
        "    return r\n",
        "\n",
        "\n",
        "# Set up the Gradio interface\n",
        "with gr.Blocks(title=\"NER Task\") as ner_interface:\n",
        "    input_text = gr.Textbox(label=\"Text input\", placeholder=\"Enter your text here\")\n",
        "    labels = gr.Textbox(label=\"Labels\", placeholder=\"Enter your labels here (comma separated)\", scale=2)\n",
        "    threshold = gr.Slider(0, 1, value=0.3, step=0.01, label=\"Threshold\", info=\"Lower the threshold to increase how many entities get predicted.\")\n",
        "    nested_ner = gr.Checkbox(label=\"Nested NER\", info=\"Allow for nested NER?\")\n",
        "    output = gr.HighlightedText(label=\"Predicted Entities\")\n",
        "    submit_btn = gr.Button(\"Submit\")\n",
        "    examples = gr.Examples(\n",
        "    ner_examples,\n",
        "    fn=process,\n",
        "    inputs=[input_text, labels, threshold, nested_ner],\n",
        "    outputs=output,\n",
        "    cache_examples=True\n",
        "    )\n",
        "    theme=gr.themes.Base()\n",
        "\n",
        "    input_text.submit(fn=process, inputs=[input_text, labels, threshold, nested_ner], outputs=output)\n",
        "    labels.submit(fn=process, inputs=[input_text, labels, threshold, nested_ner], outputs=output)\n",
        "    threshold.release(fn=process, inputs=[input_text, labels, threshold, nested_ner], outputs=output)\n",
        "    submit_btn.click(fn=process, inputs=[input_text, labels, threshold, nested_ner], outputs=output)\n",
        "    nested_ner.change(fn=process, inputs=[input_text, labels, threshold, nested_ner], outputs=output)\n",
        "\n",
        "\n",
        "# Run the app with ngrok\n",
        "if __name__ == \"__main__\":\n",
        "    # Get an ngrok authtoken and set it (replace \"YOUR_AUTHTOKEN\" with your actual token)\n",
        "    # You can get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "    ngrok_token = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "    if ngrok_token:\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "        # Open a tunnel on port 7860 (Gradio's default port)\n",
        "        public_url = ngrok.connect(7860)\n",
        "        print(f\"Public URL: {public_url}\")\n",
        "        ner_interface.launch(server_port=7860)\n",
        "\n",
        "    else:\n",
        "        print(\"Please set the NGROK_AUTH_TOKEN environment variable with your ngrok authtoken.\")\n",
        "        print(\"You can get your authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "        # Fallback to local launch if no token provided (for local testing)\n",
        "        ner_interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6cbae6f13ed243eeb5e76ddb5af150de",
            "e31cb77e3043410c8ee33b08256dc3e3",
            "73ab4243bfcc45cc9698606b6fa84155",
            "3166ca97af91476eb1b8a294e76fc9d6",
            "5d9d4ce03c664c26863c378447ff784b",
            "25567e29767549ba81de8928738ce788",
            "41b568ab56354d8a943badc4039ce4d9",
            "006ed44dbb514d0d88afd7df6a8eae12",
            "0acc9bf2722942a49fae5590fc5ceda1",
            "1561392e9b71492c8b4358ea53e72432",
            "603f3ef46df74ce6a88c984a2ba41679"
          ]
        },
        "id": "MVTpA7tuCPGV",
        "outputId": "ea7abac3-0f5f-456d-bca1-42d7e19d3d57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cbae6f13ed243eeb5e76ddb5af150de"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save this code in a file named \"ner_app.py\"\n",
        "%%writefile ner_app.py\n",
        "import streamlit as st\n",
        "from typing import Dict, Union\n",
        "from gliner import GLiNER\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"NER App\", layout=\"wide\")\n",
        "\n",
        "# Function to merge adjacent entities of the same type\n",
        "def merge_entities(entities):\n",
        "    if not entities:\n",
        "        return []\n",
        "    merged = []\n",
        "    current = entities[0]\n",
        "    for next_entity in entities[1:]:\n",
        "        if next_entity['entity'] == current['entity'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
        "            current['word'] += ' ' + next_entity['word']\n",
        "            current['end'] = next_entity['end']\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = next_entity\n",
        "    merged.append(current)\n",
        "    return merged\n",
        "\n",
        "# Load the model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return GLiNER.from_pretrained(\"knowledgator/gliner-multitask-v1.0\").to(\"cpu\")\n",
        "\n",
        "# Process text through the NER model\n",
        "def process_text(text, labels, threshold, nested_ner):\n",
        "    model = load_model()\n",
        "    labels = [label.strip() for label in labels.split(\",\")]\n",
        "\n",
        "    entities = [\n",
        "        {\n",
        "            \"entity\": entity[\"label\"],\n",
        "            \"word\": entity[\"text\"],\n",
        "            \"start\": entity[\"start\"],\n",
        "            \"end\": entity[\"end\"],\n",
        "            \"score\": entity[\"score\"],\n",
        "        }\n",
        "        for entity in model.predict_entities(\n",
        "            text, labels, flat_ner=not nested_ner, threshold=threshold\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return merge_entities(entities)\n",
        "\n",
        "# Sample text for example\n",
        "sample_text = \"\"\"I recently purchased the Sony WH-1000XM4 Wireless Noise-Canceling Headphones from Amazon and I must say, I'm thoroughly impressed. The package arrived in New York within 2 days, thanks to Amazon Prime's expedited shipping.\n",
        "\n",
        "The headphones themselves are remarkable. The noise-canceling feature works like a charm in the bustling city environment, and the 30-hour battery life means I don't have to charge them every day. Connecting them to my Samsung Galaxy S21 was a breeze, and the sound quality is second to none.\n",
        "\n",
        "I also appreciated the customer service from Amazon when I had a question about the warranty. They responded within an hour and provided all the information I needed.\n",
        "\n",
        "However, the headphones did not come with a hard case, which was listed in the product description. I contacted Amazon, and they offered a 10% discount on my next purchase as an apology.\n",
        "\n",
        "Overall, I'd give these headphones a 4.5/5 rating and highly recommend them to anyone looking for top-notch quality in both product and service.\"\"\"\n",
        "\n",
        "sample_labels = \"product, brand, location, features, rating\"\n",
        "\n",
        "# Main app function\n",
        "def main():\n",
        "    st.title(\"Named Entity Recognition App\")\n",
        "    st.write(\"Identify custom entities in your text using the GLiNER model\")\n",
        "\n",
        "    # Sidebar for parameters\n",
        "    st.sidebar.header(\"Model Parameters\")\n",
        "    threshold = st.sidebar.slider(\"Confidence Threshold\", 0.0, 1.0, 0.3, 0.01)\n",
        "    nested_ner = st.sidebar.checkbox(\"Enable Nested NER\", value=False)\n",
        "\n",
        "    # Main content\n",
        "    text_input = st.text_area(\"Enter your text:\", height=200, value=sample_text)\n",
        "    labels_input = st.text_input(\"Entity types (comma separated):\", value=sample_labels)\n",
        "\n",
        "    if st.button(\"Identify Entities\"):\n",
        "        if not text_input or not labels_input:\n",
        "            st.error(\"Please enter both text and entity types\")\n",
        "            return\n",
        "\n",
        "        with st.spinner(\"Processing...\"):\n",
        "            entities = process_text(text_input, labels_input, threshold, nested_ner)\n",
        "\n",
        "            if not entities:\n",
        "                st.info(\"No entities found with current settings. Try lowering the threshold.\")\n",
        "            else:\n",
        "                # Display highlighted text\n",
        "                st.subheader(\"Identified Entities\")\n",
        "                html_output = text_input\n",
        "\n",
        "                # Insert highlights from end to beginning\n",
        "                for entity in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
        "                    start = entity['start']\n",
        "                    end = entity['end']\n",
        "                    entity_type = entity['entity']\n",
        "                    entity_text = entity['word']\n",
        "\n",
        "                    # Generate color based on entity type\n",
        "                    color_hash = hash(entity_type) % 360\n",
        "                    bgcolor = f\"hsl({color_hash}, 70%, 80%)\"\n",
        "\n",
        "                    highlight_html = f'<mark style=\"background-color: {bgcolor};\" title=\"{entity_type}\">{entity_text}</mark>'\n",
        "                    html_output = html_output[:start] + highlight_html + html_output[end:]\n",
        "\n",
        "                st.markdown(html_output, unsafe_allow_html=True)\n",
        "\n",
        "                # Display entities table\n",
        "                st.subheader(\"Entity Details\")\n",
        "                entity_df = pd.DataFrame(entities)\n",
        "                if 'score' in entity_df.columns:\n",
        "                    entity_df['score'] = entity_df['score'].round(3)\n",
        "                st.dataframe(entity_df)\n",
        "\n",
        "# For running in Colab with pyngrok\n",
        "def run_with_ngrok():\n",
        "    # Set up ngrok\n",
        "    ngrok.set_auth_token(userdata.get('NGROK_AUTH_TOKEN'))\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    public_url = ngrok.connect(port=8501)\n",
        "    st.success(f\"App running at: {public_url}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Colab\n",
        "    import os\n",
        "    is_colab = 'COLAB_GPU' in os.environ\n",
        "\n",
        "    if is_colab:\n",
        "        run_with_ngrok()\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbIBLDIpCO67",
        "outputId": "f72c24a4-4507-49b4-e530-3e4aac9d4a2f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ner_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save this code in a file named \"ner_app.py\"\n",
        "%%writefile ner_app.py\n",
        "# Save this code in a file named \"ner_app.py\"\n",
        "import streamlit as st\n",
        "from typing import Dict, Union\n",
        "from gliner import GLiNER\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"NER App\", layout=\"wide\")\n",
        "\n",
        "# Function to merge adjacent entities of the same type\n",
        "def merge_entities(entities):\n",
        "    if not entities:\n",
        "        return []\n",
        "    merged = []\n",
        "    current = entities[0]\n",
        "    for next_entity in entities[1:]:\n",
        "        if next_entity['entity'] == current['entity'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
        "            current['word'] += ' ' + next_entity['word']\n",
        "            current['end'] = next_entity['end']\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = next_entity\n",
        "    merged.append(current)\n",
        "    return merged\n",
        "\n",
        "# Load the model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return GLiNER.from_pretrained(\"knowledgator/gliner-multitask-v1.0\").to(\"cpu\")\n",
        "\n",
        "# Process text through the NER model\n",
        "def process_text(text, labels, threshold, nested_ner):\n",
        "    model = load_model()\n",
        "    labels = [label.strip() for label in labels.split(\",\")]\n",
        "\n",
        "    entities = [\n",
        "        {\n",
        "            \"entity\": entity[\"label\"],\n",
        "            \"word\": entity[\"text\"],\n",
        "            \"start\": entity[\"start\"],\n",
        "            \"end\": entity[\"end\"],\n",
        "            \"score\": entity[\"score\"],\n",
        "        }\n",
        "        for entity in model.predict_entities(\n",
        "            text, labels, flat_ner=not nested_ner, threshold=threshold\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return merge_entities(entities)\n",
        "\n",
        "# Sample text for example\n",
        "sample_text = \"\"\"I recently purchased the Sony WH-1000XM4 Wireless Noise-Canceling Headphones from Amazon and I must say, I'm thoroughly impressed. The package arrived in New York within 2 days, thanks to Amazon Prime's expedited shipping.\n",
        "\n",
        "The headphones themselves are remarkable. The noise-canceling feature works like a charm in the bustling city environment, and the 30-hour battery life means I don't have to charge them every day. Connecting them to my Samsung Galaxy S21 was a breeze, and the sound quality is second to none.\n",
        "\n",
        "I also appreciated the customer service from Amazon when I had a question about the warranty. They responded within an hour and provided all the information I needed.\n",
        "\n",
        "However, the headphones did not come with a hard case, which was listed in the product description. I contacted Amazon, and they offered a 10% discount on my next purchase as an apology.\n",
        "\n",
        "Overall, I'd give these headphones a 4.5/5 rating and highly recommend them to anyone looking for top-notch quality in both product and service.\"\"\"\n",
        "\n",
        "sample_labels = \"product, brand, location, features, rating\"\n",
        "\n",
        "# Main app function\n",
        "def main():\n",
        "    st.title(\"Named Entity Recognition App\")\n",
        "    st.write(\"Identify custom entities in your text using the GLiNER model\")\n",
        "\n",
        "    # Sidebar for parameters\n",
        "    st.sidebar.header(\"Model Parameters\")\n",
        "    threshold = st.sidebar.slider(\"Confidence Threshold\", 0.0, 1.0, 0.3, 0.01)\n",
        "    nested_ner = st.sidebar.checkbox(\"Enable Nested NER\", value=False)\n",
        "\n",
        "    # Main content\n",
        "    text_input = st.text_area(\"Enter your text:\", height=200, value=sample_text)\n",
        "    labels_input = st.text_input(\"Entity types (comma separated):\", value=sample_labels)\n",
        "\n",
        "    if st.button(\"Identify Entities\"):\n",
        "        if not text_input or not labels_input:\n",
        "            st.error(\"Please enter both text and entity types\")\n",
        "            return\n",
        "\n",
        "        with st.spinner(\"Processing...\"):\n",
        "            entities = process_text(text_input, labels_input, threshold, nested_ner)\n",
        "\n",
        "            if not entities:\n",
        "                st.info(\"No entities found with current settings. Try lowering the threshold.\")\n",
        "            else:\n",
        "                # Display highlighted text\n",
        "                st.subheader(\"Identified Entities\")\n",
        "                html_output = text_input\n",
        "\n",
        "                # Insert highlights from end to beginning\n",
        "                for entity in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
        "                    start = entity['start']\n",
        "                    end = entity['end']\n",
        "                    entity_type = entity['entity']\n",
        "                    entity_text = entity['word']\n",
        "\n",
        "                    # Generate color based on entity type\n",
        "                    color_hash = hash(entity_type) % 360\n",
        "                    bgcolor = f\"hsl({color_hash}, 70%, 80%)\"\n",
        "\n",
        "                    highlight_html = f'<mark style=\"background-color: {bgcolor};\" title=\"{entity_type}\">{entity_text}</mark>'\n",
        "                    html_output = html_output[:start] + highlight_html + html_output[end:]\n",
        "\n",
        "                st.markdown(html_output, unsafe_allow_html=True)\n",
        "\n",
        "                # Display entities table\n",
        "                st.subheader(\"Entity Details\")\n",
        "                entity_df = pd.DataFrame(entities)\n",
        "                if 'score' in entity_df.columns:\n",
        "                    entity_df['score'] = entity_df['score'].round(3)\n",
        "                st.dataframe(entity_df)\n",
        "\n",
        "# For running in Colab with pyngrok\n",
        "def run_with_ngrok():\n",
        "    # Get ngrok auth token from environment variable\n",
        "    ngrok_token = os.environ.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "    if ngrok_token:\n",
        "        # Set up ngrok with the token\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "        # Start ngrok tunnel\n",
        "        public_url = ngrok.connect(port=8501)\n",
        "        st.success(f\"App running at: {public_url}\")\n",
        "        print(f\"Public URL: {public_url}\")\n",
        "    else:\n",
        "        st.error(\"NGROK_AUTH_TOKEN environment variable not found. Public URL will not be available.\")\n",
        "        print(\"Error: NGROK_AUTH_TOKEN environment variable not found\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Colab\n",
        "    import os\n",
        "    is_colab = 'COLAB_GPU' in os.environ\n",
        "\n",
        "    if is_colab:\n",
        "        run_with_ngrok()\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pMobJsHCPA3",
        "outputId": "99afe054-ac43-4881-cabb-1b079eaaf9fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ner_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ner_app2.py\n",
        "# Save this code in a file named \"ner_app.py\"\n",
        "import streamlit as st\n",
        "from typing import Dict, Union\n",
        "from gliner import GLiNER\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"NER App\", layout=\"wide\")\n",
        "\n",
        "# Function to merge adjacent entities of the same type\n",
        "def merge_entities(entities):\n",
        "    if not entities:\n",
        "        return []\n",
        "    merged = []\n",
        "    current = entities[0]\n",
        "    for next_entity in entities[1:]:\n",
        "        if next_entity['entity'] == current['entity'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
        "            current['word'] += ' ' + next_entity['word']\n",
        "            current['end'] = next_entity['end']\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = next_entity\n",
        "    merged.append(current)\n",
        "    return merged\n",
        "\n",
        "# Load the model\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return GLiNER.from_pretrained(\"knowledgator/gliner-multitask-v1.0\").to(\"cpu\")\n",
        "\n",
        "# Process text through the NER model\n",
        "def process_text(text, labels, threshold, nested_ner):\n",
        "    model = load_model()\n",
        "    labels = [label.strip() for label in labels.split(\",\")]\n",
        "\n",
        "    entities = [\n",
        "        {\n",
        "            \"entity\": entity[\"label\"],\n",
        "            \"word\": entity[\"text\"],\n",
        "            \"start\": entity[\"start\"],\n",
        "            \"end\": entity[\"end\"],\n",
        "            \"score\": entity[\"score\"],\n",
        "        }\n",
        "        for entity in model.predict_entities(\n",
        "            text, labels, flat_ner=not nested_ner, threshold=threshold\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return merge_entities(entities)\n",
        "\n",
        "# Improved function to safely highlight entities in text\n",
        "def highlight_entities(text, entities):\n",
        "    # Sort entities by start position in descending order to avoid offset issues\n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "\n",
        "    # Create a list of characters from the text\n",
        "    chars = list(text)\n",
        "\n",
        "    # Process each entity\n",
        "    for entity in sorted_entities:\n",
        "        start = entity['start']\n",
        "        end = entity['end']\n",
        "        entity_type = entity['entity']\n",
        "\n",
        "        # Generate color based on entity type\n",
        "        color_hash = hash(entity_type) % 360\n",
        "        bgcolor = f\"hsl({color_hash}, 70%, 80%)\"\n",
        "\n",
        "        # Create HTML tags for the entity\n",
        "        open_tag = f'<span style=\"background-color: {bgcolor}; padding: 1px 3px; border-radius: 3px;\" title=\"{entity_type}\">'\n",
        "        close_tag = '</span>'\n",
        "\n",
        "        # Insert the tags\n",
        "        chars.insert(end, close_tag)\n",
        "        chars.insert(start, open_tag)\n",
        "\n",
        "    # Join the characters back into a string and replace newlines with <br> tags\n",
        "    highlighted_text = ''.join(chars).replace('\\n', '<br>')\n",
        "\n",
        "    # Wrap in a div with appropriate styling\n",
        "    return f'<div style=\"line-height: 1.6; white-space: pre-wrap; font-family: sans-serif;\">{highlighted_text}</div>'\n",
        "\n",
        "# Sample text for example\n",
        "sample_text = \"\"\"I recently purchased the Sony WH-1000XM4 Wireless Noise-Canceling Headphones from Amazon and I must say, I'm thoroughly impressed. The package arrived in New York within 2 days, thanks to Amazon Prime's expedited shipping.\n",
        "\n",
        "The headphones themselves are remarkable. The noise-canceling feature works like a charm in the bustling city environment, and the 30-hour battery life means I don't have to charge them every day. Connecting them to my Samsung Galaxy S21 was a breeze, and the sound quality is second to none.\n",
        "\n",
        "I also appreciated the customer service from Amazon when I had a question about the warranty. They responded within an hour and provided all the information I needed.\n",
        "\n",
        "However, the headphones did not come with a hard case, which was listed in the product description. I contacted Amazon, and they offered a 10% discount on my next purchase as an apology.\n",
        "\n",
        "Overall, I'd give these headphones a 4.5/5 rating and highly recommend them to anyone looking for top-notch quality in both product and service.\"\"\"\n",
        "\n",
        "sample_labels = \"product, brand, location, features, rating\"\n",
        "\n",
        "# Main app function\n",
        "def main():\n",
        "    st.title(\"Named Entity Recognition App\")\n",
        "    st.write(\"Identify custom entities in your text using the GLiNER model\")\n",
        "\n",
        "    # Sidebar for parameters\n",
        "    st.sidebar.header(\"Model Parameters\")\n",
        "    threshold = st.sidebar.slider(\"Confidence Threshold\", 0.0, 1.0, 0.3, 0.01)\n",
        "    nested_ner = st.sidebar.checkbox(\"Enable Nested NER\", value=False)\n",
        "\n",
        "    # Main content\n",
        "    text_input = st.text_area(\"Enter your text:\", height=200, value=sample_text)\n",
        "    labels_input = st.text_input(\"Entity types (comma separated):\", value=sample_labels)\n",
        "\n",
        "    if st.button(\"Identify Entities\"):\n",
        "        if not text_input or not labels_input:\n",
        "            st.error(\"Please enter both text and entity types\")\n",
        "            return\n",
        "\n",
        "        with st.spinner(\"Processing...\"):\n",
        "            entities = process_text(text_input, labels_input, threshold, nested_ner)\n",
        "\n",
        "            if not entities:\n",
        "                st.info(\"No entities found with current settings. Try lowering the threshold.\")\n",
        "            else:\n",
        "                # Display highlighted text\n",
        "                st.subheader(\"Identified Entities\")\n",
        "\n",
        "                # Use the improved highlighting function\n",
        "                html_output = highlight_entities(text_input, entities)\n",
        "                st.markdown(html_output, unsafe_allow_html=True)\n",
        "\n",
        "                # Display entities table\n",
        "                st.subheader(\"Entity Details\")\n",
        "                entity_df = pd.DataFrame(entities)\n",
        "                if 'score' in entity_df.columns:\n",
        "                    entity_df['score'] = entity_df['score'].round(3)\n",
        "                st.dataframe(entity_df)\n",
        "\n",
        "                # Download options\n",
        "                st.subheader(\"Download Results\")\n",
        "\n",
        "                # CSV download button for entity data\n",
        "                csv = entity_df.to_csv(index=False)\n",
        "                st.download_button(\n",
        "                    label=\"Download Entities as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=\"entities.csv\",\n",
        "                    mime=\"text/csv\",\n",
        "                )\n",
        "\n",
        "                # Plain text download with annotations\n",
        "                annotated_text = text_input\n",
        "                for entity in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
        "                    start = entity['start']\n",
        "                    end = entity['end']\n",
        "                    entity_type = entity['entity']\n",
        "                    annotated_text = annotated_text[:start] + f\"[{annotated_text[start:end]}]({entity_type})\" + annotated_text[end:]\n",
        "\n",
        "                st.download_button(\n",
        "                    label=\"Download Annotated Text\",\n",
        "                    data=annotated_text,\n",
        "                    file_name=\"annotated_text.txt\",\n",
        "                    mime=\"text/plain\",\n",
        "                )\n",
        "\n",
        "# For running in Colab with pyngrok\n",
        "def run_with_ngrok():\n",
        "    # Get ngrok auth token from environment variable\n",
        "    ngrok_token = os.environ.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "    if ngrok_token:\n",
        "        # Set up ngrok with the token\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "        try:\n",
        "            # Start ngrok tunnel\n",
        "            public_url = ngrok.connect(port=8501)\n",
        "            st.success(f\"App running at: {public_url}\")\n",
        "            print(f\"Public URL: {public_url}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to create ngrok tunnel: {str(e)}\")\n",
        "            print(f\"Error creating ngrok tunnel: {str(e)}\")\n",
        "    else:\n",
        "        st.error(\"NGROK_AUTH_TOKEN environment variable not found. Public URL will not be available.\")\n",
        "        print(\"Error: NGROK_AUTH_TOKEN environment variable not found\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check if running in Colab\n",
        "    import os\n",
        "    is_colab = 'COLAB_GPU' in os.environ\n",
        "\n",
        "    if is_colab:\n",
        "        run_with_ngrok()\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdaSwhHXNYoQ",
        "outputId": "a723aa15-6965-4f3d-8ea6-e7cb864c7ab8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ner_app2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ner_app3.py from google\n",
        "%%writefile ner_app3.py\n",
        "import streamlit as st\n",
        "from typing import Dict, Union\n",
        "from gliner import GLiNER\n",
        "from pyngrok import ngrok\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import torch  # Import torch\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"NER App\", layout=\"wide\")\n",
        "\n",
        "# Function to merge adjacent entities of the same type\n",
        "def merge_entities(entities):\n",
        "    if not entities:\n",
        "        return []\n",
        "    merged = []\n",
        "    current = entities[0]\n",
        "    for next_entity in entities[1:]:\n",
        "        if next_entity['entity'] == current['entity'] and (next_entity['start'] == current['end'] + 1 or next_entity['start'] == current['end']):\n",
        "            current['word'] += ' ' + next_entity['word']\n",
        "            current['end'] = next_entity['end']\n",
        "        else:\n",
        "            merged.append(current)\n",
        "            current = next_entity\n",
        "    merged.append(current)\n",
        "    return merged\n",
        "\n",
        "# Load the model (using GPU if available)\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    return GLiNER.from_pretrained(\"knowledgator/gliner-multitask-v1.0\").to(device)\n",
        "\n",
        "# Process text through the NER model\n",
        "def process_text(text, labels, threshold, nested_ner):\n",
        "    model = load_model()\n",
        "    labels = [label.strip() for label in labels.split(\",\")]\n",
        "    try:\n",
        "        entities = [\n",
        "            {\n",
        "                \"entity\": entity[\"label\"],\n",
        "                \"word\": entity[\"text\"],\n",
        "                \"start\": entity[\"start\"],\n",
        "                \"end\": entity[\"end\"],\n",
        "                \"score\": entity[\"score\"],\n",
        "            }\n",
        "            for entity in model.predict_entities(\n",
        "                text, labels, flat_ner=not nested_ner, threshold=threshold\n",
        "            )\n",
        "        ]\n",
        "        return merge_entities(entities)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error during model prediction: {e}\")\n",
        "        return []\n",
        "\n",
        "# Improved function to safely highlight entities in text\n",
        "def highlight_entities(text, entities):\n",
        "    # Sort entities by start position in descending order to avoid offset issues\n",
        "    sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
        "    chars = list(text)\n",
        "    for entity in sorted_entities:\n",
        "        start = entity['start']\n",
        "        end = entity['end']\n",
        "        entity_type = entity['entity']\n",
        "        color_hash = hash(entity_type) % 360\n",
        "        bgcolor = f\"hsl({color_hash}, 70%, 80%)\"\n",
        "        open_tag = f'<span style=\"background-color: {bgcolor}; padding: 1px 3px; border-radius: 3px;\" title=\"{entity_type}\">'\n",
        "        close_tag = '</span>'\n",
        "        chars.insert(end, close_tag)\n",
        "        chars.insert(start, open_tag)\n",
        "    highlighted_text = ''.join(chars).replace('\\n', '<br>')\n",
        "    return f'<div style=\"line-height: 1.6; white-space: pre-wrap; font-family: sans-serif;\">{highlighted_text}</div>'\n",
        "\n",
        "# Sample text for example\n",
        "sample_text = \"\"\"I recently purchased the Sony WH-1000XM4 Wireless Noise-Canceling Headphones from Amazon and I must say, I'm thoroughly impressed. The package arrived in New York within 2 days, thanks to Amazon Prime's expedited shipping.\n",
        "\n",
        "The headphones themselves are remarkable. The noise-canceling feature works like a charm in the bustling city environment, and the 30-hour battery life means I don't have to charge them every day. Connecting them to my Samsung Galaxy S21 was a breeze, and the sound quality is second to none.\n",
        "\n",
        "I also appreciated the customer service from Amazon when I had a question about the warranty. They responded within an hour and provided all the information I needed.\n",
        "\n",
        "However, the headphones did not come with a hard case, which was listed in the product description. I contacted Amazon, and they offered a 10% discount on my next purchase as an apology.\n",
        "\n",
        "Overall, I'd give these headphones a 4.5/5 rating and highly recommend them to anyone looking for top-notch quality in both product and service.\"\"\"\n",
        "\n",
        "sample_labels = \"product, brand, location, features, rating\"\n",
        "\n",
        "# Main app function\n",
        "def main():\n",
        "    st.title(\"Named Entity Recognition App\")\n",
        "    st.write(\"Identify custom entities in your text using the GLiNER model\")\n",
        "    st.sidebar.header(\"Model Parameters\")\n",
        "    threshold = st.sidebar.slider(\"Confidence Threshold\", 0.0, 1.0, 0.3, 0.01)\n",
        "    nested_ner = st.sidebar.checkbox(\"Enable Nested NER\", value=False)\n",
        "    text_input = st.text_area(\"Enter your text:\", height=200, value=sample_text)\n",
        "    labels_input = st.text_input(\"Entity types (comma separated):\", value=sample_labels)\n",
        "    if st.button(\"Identify Entities\"):\n",
        "        if not text_input or not labels_input:\n",
        "            st.error(\"Please enter both text and entity types\")\n",
        "            return\n",
        "        with st.spinner(\"Processing...\"):\n",
        "            entities = process_text(text_input, labels_input, threshold, nested_ner)\n",
        "            if not entities:\n",
        "                st.info(\"No entities found with current settings. Try lowering the threshold.\")\n",
        "            else:\n",
        "                st.subheader(\"Identified Entities\")\n",
        "                html_output = highlight_entities(text_input, entities)\n",
        "                st.markdown(html_output, unsafe_allow_html=True)\n",
        "                st.subheader(\"Entity Details\")\n",
        "                entity_df = pd.DataFrame(entities)\n",
        "                if 'score' in entity_df.columns:\n",
        "                    entity_df['score'] = entity_df['score'].round(3)\n",
        "                st.dataframe(entity_df)\n",
        "                st.subheader(\"Download Results\")\n",
        "                csv = entity_df.to_csv(index=False)\n",
        "                st.download_button(\n",
        "                    label=\"Download Entities as CSV\",\n",
        "                    data=csv,\n",
        "                    file_name=\"entities.csv\",\n",
        "                    mime=\"text/csv\",\n",
        "                )\n",
        "                annotated_text = text_input\n",
        "                for entity in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
        "                    start = entity['start']\n",
        "                    end = entity['end']\n",
        "                    entity_type = entity['entity']\n",
        "                    annotated_text = annotated_text[:start] + f\"[{annotated_text[start:end]}]({entity_type})\" + annotated_text[end:]\n",
        "                st.download_button(\n",
        "                    label=\"Download Annotated Text\",\n",
        "                    data=annotated_text,\n",
        "                    file_name=\"annotated_text.txt\",\n",
        "                    mime=\"text/plain\",\n",
        "                )\n",
        "\n",
        "# For running in Colab with pyngrok\n",
        "def run_with_ngrok():\n",
        "    # Get ngrok auth token from environment variable\n",
        "    ngrok_token = os.environ.get('NGROK_AUTH_TOKEN')\n",
        "    if ngrok_token:\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "        try:\n",
        "            public_url = ngrok.connect(port=8501)\n",
        "            st.success(f\"App running at: {public_url}\")\n",
        "            print(f\"Public URL: {public_url}\")  # Print for Colab output\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to create ngrok tunnel: {str(e)}\")\n",
        "            print(f\"Error creating ngrok tunnel: {str(e)}\") # Print for Colab output\n",
        "    else:\n",
        "        st.error(\"NGROK_AUTH_TOKEN environment variable not found. Public URL will not be available.\")\n",
        "        print(\"Error: NGROK_AUTH_TOKEN environment variable not found\")  #Print\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "    is_colab = 'COLAB_GPU' in os.environ\n",
        "    if is_colab:\n",
        "        run_with_ngrok()\n",
        "    main()"
      ],
      "metadata": {
        "id": "px9qLLQkQhiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # First, write the app code to a file\n",
        "# %%writefile ner_app.py\n",
        "# # [The entire code from the artifact above will be written to the file]\n",
        "\n",
        "# # Install required packages\n",
        "# !pip install streamlit pyngrok gliner -q\n",
        "\n",
        "# Get the ngrok auth token from userdata\n",
        "from google.colab import userdata\n",
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "# Kill any existing Streamlit processes\n",
        "!pkill -f streamlit || true\n",
        "\n",
        "# Start Streamlit with the token as an environment variable\n",
        "!streamlit run ner_app2.py --server.port=8501 &\n",
        "\n",
        "# Give Streamlit a moment to start\n",
        "import time\n",
        "time.sleep(7)\n",
        "\n",
        "# Check if the app is running\n",
        "!ps aux | grep streamlit\n",
        "\n",
        "# Create and display the public URL manually if needed\n",
        "from pyngrok import ngrok\n",
        "# Configure ngrok with the token\n",
        "ngrok.set_auth_token(ngrok_token)\n",
        "\n",
        "# Kill any existing tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "# Start a new tunnel\n",
        "public_url = ngrok.connect(port=8501)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"📢 Access your app at this URL: {public_url}\")\n",
        "print(\"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "VRYdb4zxNy6S",
        "outputId": "86761f0f-eb50-44ea-a807-103943ae35ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.230.12.212:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "root       34157  0.0  0.0   6484  2172 ?        S    21:39   0:00 grep streamlit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-03-05T21:39:34+0000 lvl=warn msg=\"invalid tunnel configuration\" pg=/api/tunnels id=695113a85a366276 err=\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokHTTPError",
          "evalue": "ngrok client exception, API returned 400: {\"error_code\":102,\"status_code\":400,\"msg\":\"invalid tunnel configuration\",\"details\":{\"err\":\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"}}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-a1b144c01397>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Start a new tunnel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"📢 Access your app at this URL: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    356\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    357\u001b[0m                          pyngrok_config, api_url)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response {status_code}: {response_data.strip()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n\u001b[0m\u001b[1;32m    579\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 400: {\"error_code\":102,\"status_code\":400,\"msg\":\"invalid tunnel configuration\",\"details\":{\"err\":\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "import logging\n",
        "import requests\n",
        "\n",
        "# Configure logging (helps with debugging)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# 1. Get ngrok Auth Token\n",
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "if not ngrok_token:\n",
        "    print(\"ERROR: NGROK_AUTH_TOKEN not found in userdata.  Please set it.\", file=sys.stderr)\n",
        "    sys.exit(1)\n",
        "\n",
        "# 2. Kill Existing Processes (More Robustly)\n",
        "def kill_processes():\n",
        "    try:\n",
        "        subprocess.run([\"pkill\", \"-f\", \"streamlit\"], check=True, capture_output=True)\n",
        "        logging.info(\"Killed existing Streamlit processes.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        logging.warning(f\"Error killing Streamlit processes (likely none running): {e}\")\n",
        "\n",
        "    try:\n",
        "        ngrok.kill()\n",
        "        logging.info(\"Killed existing ngrok tunnels.\")\n",
        "    except Exception as e:\n",
        "        logging.warning(f\"Error killing ngrok tunnels: {e}\")\n",
        "\n",
        "kill_processes()  # Kill processes at the start\n",
        "\n",
        "\n",
        "# 3. Start Streamlit (and Wait for it to Be Ready)\n",
        "def start_streamlit(script_path, port=8501):\n",
        "    \"\"\"Starts Streamlit and waits for it to become accessible.\"\"\"\n",
        "    logging.info(f\"Starting Streamlit on port {port}...\")\n",
        "    process = subprocess.Popen(\n",
        "        [\"streamlit\", \"run\", script_path, f\"--server.port={port}\", \"--server.headless=true\"],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True  # Important for reading output as strings\n",
        "    )\n",
        "\n",
        "    # Wait for Streamlit to be ready (check for \"running on\" message)\n",
        "    start_time = time.time()\n",
        "    timeout = 60  # Maximum wait time in seconds\n",
        "    while True:\n",
        "        if time.time() - start_time > timeout:\n",
        "            logging.error(\"Timeout: Streamlit did not start within the timeout period.\")\n",
        "            process.terminate()  # Kill the process if it times out.\n",
        "            # Check for errors by reading the standard error of the process\n",
        "            stderr_output = process.stderr.read()\n",
        "            if stderr_output:\n",
        "                logging.error(f\"Streamlit stderr:\\n{stderr_output}\")\n",
        "            return None\n",
        "\n",
        "        output_line = process.stdout.readline() # read a line from stdout\n",
        "        if output_line:\n",
        "          logging.info(f\"Streamlit Output: {output_line.strip()}\")\n",
        "        if \"running on\" in output_line.lower() or \"External URL:\" in output_line: # look for indication of successful startup\n",
        "            logging.info(\"Streamlit is running.\")\n",
        "            break\n",
        "        if process.poll() is not None: # check if streamlit process has exited,\n",
        "                                      #None means it is still running\n",
        "            logging.error(\"Streamlit process terminated unexpectedly.\")\n",
        "            stderr_output = process.stderr.read()\n",
        "            if stderr_output:\n",
        "                logging.error(f\"Streamlit stderr:\\n{stderr_output}\")\n",
        "            return None\n",
        "        time.sleep(1)  # Check frequently, but don't spam\n",
        "\n",
        "    return process\n",
        "\n",
        "# 4.  Connect to ngrok (AFTER Streamlit is Ready)\n",
        "def connect_ngrok(port=8501):\n",
        "    \"\"\"Connects to ngrok and returns the public URL.\"\"\"\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    try:\n",
        "        public_url = ngrok.connect(port)\n",
        "        logging.info(f\"ngrok tunnel established at: {public_url}\")\n",
        "        return public_url\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error connecting to ngrok: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "# Assuming your Streamlit app script is named 'ner_app2.py'\n",
        "streamlit_process = start_streamlit(\"ner_app2.py\")\n",
        "\n",
        "if streamlit_process:\n",
        "    public_url_info = connect_ngrok()\n",
        "    if public_url_info:\n",
        "      print(\"\\n\" + \"=\"*50)\n",
        "      print(f\"📢 Access your app at this URL: {public_url_info}\")\n",
        "      print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Keep the Colab cell alive (important!)\n",
        "    try:\n",
        "        while True:\n",
        "            time.sleep(60) #keep the colab kernel alive\n",
        "            if streamlit_process.poll() is not None: # check if streamlit is still running\n",
        "                logging.warning(\"Streamlit process terminated. Restarting...\")\n",
        "                kill_processes()\n",
        "                streamlit_process = start_streamlit(\"ner_app2.py\")\n",
        "                if streamlit_process:\n",
        "                    public_url_info = connect_ngrok()  # Reconnect ngrok\n",
        "                    if public_url_info:\n",
        "                        print(\"\\n\" + \"=\" * 50)\n",
        "                        print(f\"📢 Access your app at this URL: {public_url_info}\")\n",
        "                        print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        logging.info(\"Stopping Streamlit and ngrok...\")\n",
        "        kill_processes()\n",
        "        logging.info(\"Exiting.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iysOH1lcP87q",
        "outputId": "b98c02c9-b1e9-4884-ba30-c868ea78800d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Error killing Streamlit processes (likely none running): Command '['pkill', '-f', 'streamlit']' returned non-zero exit status 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "📢 Access your app at this URL: NgrokTunnel: \"https://f1ee-35-230-12-212.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRODUCT, BRAND, SPECIFICATION, COLOR, FEATURE, PRICE, PROBLEM, RESOLUTION, SIZE, MODEL_NUMBER"
      ],
      "metadata": {
        "id": "INbCf9EyMxtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "id,query\n",
        "1,What's the price of Samsung Galaxy S23 Ultra 256GB in Phantom Black?\n",
        "2,How to fix overheating issue in 75\" Samsung QN900B Neo QLED 8K TV?\n",
        "3,Compare storage capacity between Galaxy Z Flip5 512GB and Fold4 1TB\n",
        "4,Does Samsung Bespoke Jet™ Vacuum come in Navy Blue color?\n",
        "5,Troubleshoot screen flickering on Odyssey G7 32\" gaming monitor\n",
        "6,Best Samsung soundbar with Dolby Atmos under $500\n",
        "7,How long is warranty for 55\" Samsung Frame TV 2023 model?\n",
        "8,Replace battery for Galaxy Watch5 Pro 45mm Titanium Gray\n",
        "9,Specifications for Samsung Smart Monitor M8 in Warm White\n",
        "10,Does Samsung 980 Pro 2TB SSD work with PS5?\n",
        "11,Compare Galaxy Buds2 Pro noise cancellation vs AirPods Pro\n",
        "12,Price drop alert for 85\" Samsung QLED Q80C series\n",
        "13,How to clean mold in Samsung BESPOKE 4-Door Flex refrigerator?\n",
        "14,Repair cost for cracked screen on Galaxy Tab S9 Ultra 14.6\"\n",
        "15,Energy efficiency rating of Samsung WindFree™ AC AR9500T\n",
        "16,Where to buy Samsung 980 PRO SSD 1TB with heatsink?\n",
        "17,Does Samsung S95B OLED TV support HDR10+ Gaming?\n",
        "18,How to enable 144Hz refresh rate on Odyssey Neo G9 57\" monitor?\n",
        "19,Best Samsung laptop with 16GB RAM under $1000\n",
        "20,Troubleshoot WiFi issues on Galaxy Book3 Ultra\n",
        "21,Compare colors available for Galaxy Z Fold5 vs S23 Ultra\n",
        "22,Return policy for defective Samsung T7 Shield 4TB SSD\n",
        "23,Maximum load capacity for Samsung Jet Bot™+ robot vacuum\n",
        "24,How durable is Samsung Galaxy XCover6 Pro military-grade phone?\n",
        "25,Installation cost for Samsung 3-Tone Bespoke stove\n",
        "26,Does Samsung 990 Pro 4TB SSD come with cloning software?\n",
        "27,How to replace filter in Samsung Cube Air Purifier AX46\n",
        "28,Best Samsung monitor for photo editing with color accuracy\n",
        "29,Repair Samsung Bespoke Washer error code 4E\n",
        "30,Compare charging speed: 45W vs 25W Samsung adapters\n",
        "31,Price match guarantee on Samsung HW-Q990C Soundbar\n",
        "32,How to clean Samsung AirDresser water tank?\n",
        "33,Minimum room size for Samsung 9500 BTU WindFree™ AC\n",
        "34,Does Galaxy Watch6 Classic support blood pressure monitoring?\n",
        "35,Troubleshoot delayed notifications on Galaxy S23 FE\n",
        "36,Compare battery life: Galaxy Book3 Pro vs MacBook Air M2\n",
        "37,How scratch-resistant is Samsung S95C OLED TV screen?\n",
        "38,Replacement parts for Samsung Jet™ 90 Complete vacuum\n",
        "39,Best Samsung SSD for 4K video editing\n",
        "40,Install Samsung SmartThings on Windows 11\n",
        "41,Compare cooling performance: Bespoke vs Family Hub refrigerators\n",
        "42,How to factory reset Galaxy A54 5G with broken screen?\n",
        "43,Does Samsung 27\" ViewFinity S8 monitor have HDMI 2.1?\n",
        "44,Water damage repair cost for Galaxy Buds2 Pro\n",
        "45,Best color calibration settings for S95C 65\" OLED\n",
        "46,How durable is Samsung Galaxy Tab Active4 Pro?\n",
        "47,Compare RAM options for Galaxy Book3 Ultra laptops\n",
        "48,Troubleshoot motion detection on Samsung S23 Ultra camera\n",
        "49,Replacement cost for Samsung Bespoke induction cooktop\n",
        "50,Does Galaxy Z Flip5 support wireless charging?\n",
        "51,How to enable 200MP mode on Galaxy S23 Ultra?\n",
        "52,Compare thickness: Galaxy S23 vs iPhone 14 Pro\n",
        "53,Best Samsung T7 Shield case for outdoor use\n",
        "54,How to clean Samsung Refrigerator Ice Maker mold?\n",
        "55,Maximum SD card size for Galaxy Book3 Pro 360\n",
        "56,Does Samsung 980 Pro SSD need heatsink for PS5?\n",
        "57,Repair estimate for dented Bespoke refrigerator door\n",
        "58,Compare brightness levels: QN900B vs S95C TVs\n",
        "59,How to update firmware on Samsung T7 Touch SSD\n",
        "60,Best Samsung monitor for coding with eye comfort\n",
        "61,Does Galaxy Watch6 have fall detection feature?\n",
        "62,Troubleshoot Dolby Atmos on HW-Q800C Soundbar\n",
        "63,Compare warranty periods across Samsung SSD models\n",
        "64,How to remove scratches from Galaxy Z Flip5 hinge?\n",
        "65,Best color options for Samsung Bespoke Jet™ vacuum\n",
        "66,Does Samsung 49\" Odyssey G9 support Picture-by-Picture?\n",
        "67,Installation requirements for Samsung Wall Mount Oven\n",
        "68,Compare fan speeds: Samsung Jet™ 75 vs 90 models\n",
        "69,How to replace Samsung Bespoke refrigerator water filter\n",
        "70,Best Samsung SSD for gaming laptop upgrades\n",
        "71,Does Galaxy S23 Ultra support 8K video recording?\n",
        "72,Troubleshoot uneven cooling in Samsung WindFree™ AC\n",
        "73,Compare weight: Galaxy Book3 Pro vs Surface Laptop 5\n",
        "74,How to enable Game Mode on Samsung S95B OLED TV\n",
        "75,Best Samsung monitor arm for 49\" Odyssey G9\n",
        "76,Does Galaxy Buds2 Pro have multipoint connectivity?\n",
        "77,Compare thickness: QN900B vs LG G3 OLED TVs\n",
        "78,How to clean Samsung AirDresser lint filter?\n",
        "79,Replacement cost for Galaxy Watch6 Classic rotating bezel\n",
        "80,Best Samsung SSD enclosure for 990 Pro\n",
        "81,Does Galaxy Z Fold5 support S Pen Pro?\n",
        "82,Troubleshoot Alexa integration on Samsung Frame TV\n",
        "83,Compare charging speeds: 25W vs 45W Samsung adapters\n",
        "84,How to enable Secure Folder on Galaxy S23 FE?\n",
        "85,Best color profile settings for S95C 77\" OLED\n",
        "86,Does Samsung Bespoke Jet™ work on thick carpets?\n",
        "87,Installation guide for Samsung Slide-in Gas Range\n",
        "88,Compare noise levels: Jet 90 vs Dyson V15 vacuums\n",
        "89,How to reset Samsung Bespoke Washer error code 5E\n",
        "90,Best protective case for Galaxy Z Flip5\n",
        "91,Does Galaxy Book3 Ultra have Thunderbolt 4 ports?\n",
        "92,Troubleshoot slow charging on Galaxy S23 Ultra\n",
        "93,Compare cooling systems: Odyssey G7 vs G9 monitors\n",
        "94,How to enable Eye Comfort Mode on Galaxy Tab S9\n",
        "95,Best Samsung T7 Shield configuration for photographers\n",
        "96,Does Galaxy Watch6 Classic have ECG functionality?\n",
        "97,Compare water resistance: Galaxy S23 vs S23 Ultra\n",
        "98,How to clean Samsung Bespoke Refrigerator condenser coils\n",
        "99,Best Samsung monitor for video conferencing\n",
        "100,Does Galaxy Buds2 Pro support spatial audio?"
      ],
      "metadata": {
        "id": "XefFeKkyMxwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CmC4OxSOMxzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-KKjyX1ZMx4m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMUrYNs6F362"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sz0IZWzIF31Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGZFXg9BwE89",
        "outputId": "f94beaf9-0b32-4f88-fec2-b8784c4859e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully processed queries and saved results to 'output.csv'\n",
            "                                                query    PRODUCT    BRAND  \\\n",
            "0               I want a Samsung 55-inch 4K smart TV.        NaN  Samsung   \n",
            "1   Are there any noise-canceling headphones under...        NaN      NaN   \n",
            "2                      My iPhone 13 screen is broken.  iPhone 13      NaN   \n",
            "3           Looking for a cheap laptop with 16GB RAM.        NaN      NaN   \n",
            "4     Do you have the new Sony WH-1000XM5 headphones?        NaN      NaN   \n",
            "5                      I need a black wireless mouse.        NaN      NaN   \n",
            "6                      What's the best gaming laptop?        NaN      NaN   \n",
            "7               Is the Samsung Galaxy S23 waterproof?        NaN      NaN   \n",
            "8                   My Dell XPS 15 is malfunctioning.        NaN      NaN   \n",
            "9                     Show me 4k tv with Dolby vision        NaN      NaN   \n",
            "10                          I want a black colored TV        NaN      NaN   \n",
            "11                   which is the best tv under $2000        NaN      NaN   \n",
            "\n",
            "    SPECIFICATION  COLOR  FEATURE  PRICE  PROBLEM  RESOLUTION  SIZE  \n",
            "0             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "1             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "2             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "3             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "4             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "5             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "6             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "7             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "8             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "9             NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "10            NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n",
            "11            NaN    NaN      NaN    NaN      NaN         NaN   NaN  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "def extract_attributes(queries_csv, output_csv):\n",
        "    \"\"\"\n",
        "    Extracts key attributes from a CSV file of user queries using a transformer-based NER model.\n",
        "\n",
        "    Args:\n",
        "        queries_csv: Path to the input CSV file containing a 'query' column.\n",
        "        output_csv: Path to the output CSV file where the results will be saved.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Load the data ---\n",
        "    try:\n",
        "        df = pd.read_csv(queries_csv)\n",
        "        if 'query' not in df.columns:\n",
        "            raise ValueError(\"The input CSV must contain a 'query' column.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{queries_csv}' was not found.\")\n",
        "        return\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"Error: Could not parse the CSV file '{queries_csv}'.  Check for formatting issues.\")\n",
        "        return\n",
        "    except ValueError as ve:\n",
        "        print(f\"Error: {ve}\")\n",
        "        return\n",
        "\n",
        "\n",
        "    # --- 2. Initialize the NER pipeline ---\n",
        "    # Using a pre-trained model fine-tuned for product-related entities.  'dslim/bert-base-NER' is a good general NER model.\n",
        "    # For more specific, product-focused NER, you might need to fine-tune a model yourself on a dataset of product descriptions/queries.\n",
        "    try:\n",
        "      #  tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")  #Or any suitable model\n",
        "      #  model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
        "      #  nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "        nlp = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\") #Faster and handles some edge cases\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading the NER model: {e}.  Check your Hugging Face Transformers installation and model name.\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Define entity categories (Adapt based on your needs) ---\n",
        "    #   This is crucial.  Define what constitutes a relevant entity for *your* attributes.\n",
        "    entity_categories = {\n",
        "        \"PRODUCT\": [],  # e.g., \"laptop\", \"headphones\", \"smart TV\"\n",
        "        \"BRAND\": [],  # e.g., \"Samsung\", \"Apple\", \"Sony\"\n",
        "        \"SPECIFICATION\": [],  # e.g., \"16GB RAM\", \"4K resolution\", \"wireless\"\n",
        "        \"COLOR\": [],  # e.g. \"black\", \"silver\", \"red\"\n",
        "        \"FEATURE\": [],  # e.g., \"noise-canceling\", \"waterproof\", \"voice control\"\n",
        "        \"PRICE\": [],  # e.g., \"$500\", \"under $1000\", \"cheap\"  (Might need further processing)\n",
        "        \"PROBLEM\": [],  #e.g. \"broken\", \"defective\", \"malfunctioning\"\n",
        "        \"RESOLUTION\": [],  # e.g., \"4K\", \"1080p\", \"HD\"\n",
        "        \"SIZE\": []       # e.g., \"55-inch\", \"13-inch screen\", \"small\"\n",
        "    }\n",
        "\n",
        "\n",
        "    # --- 4. Process each query ---\n",
        "    for index, row in df.iterrows():\n",
        "        query = row['query']\n",
        "        try:\n",
        "            ner_results = nlp(query)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing query '{query}': {e}\")\n",
        "            continue  # Skip to the next query\n",
        "\n",
        "        # --- 5. Extract and categorize entities ---\n",
        "        extracted_entities = {category: [] for category in entity_categories}\n",
        "\n",
        "        for entity in ner_results:\n",
        "            entity_text = entity['word']\n",
        "            entity_group = entity['entity_group']\n",
        "\n",
        "            # Add more specific logic here, based on your entity categories and 'entity_group' from the model\n",
        "            # This is where you map the model's output to YOUR desired attributes.\n",
        "            if entity_group == \"ORG\" :  # Example: Treat organizations as brands\n",
        "                extracted_entities[\"BRAND\"].append(entity_text)\n",
        "            elif entity_group == \"MISC\":   # Example: Potentially product names, specifications\n",
        "                if any(keyword in entity_text.lower() for keyword in [\"tv\", \"laptop\", \"phone\", \"headphones\"]):\n",
        "                    extracted_entities[\"PRODUCT\"].append(entity_text)\n",
        "                elif any(keyword in entity_text.lower() for keyword in [\"inch\", \"gb\", \"ram\"]):\n",
        "                     extracted_entities[\"SPECIFICATION\"].append(entity_text)\n",
        "\n",
        "            elif entity_group == \"PER\":\n",
        "              if any(keyword in entity_text.lower() for keyword in [\"tv\", \"laptop\", \"phone\", \"headphones\"]):\n",
        "                    extracted_entities[\"PRODUCT\"].append(entity_text)\n",
        "\n",
        "\n",
        "            # Add more rules as needed, based on experimentation.  This is the most crucial part!\n",
        "\n",
        "        # --- 6. Add extracted entities to the DataFrame ---\n",
        "        for category, values in extracted_entities.items():\n",
        "            # Join multiple entities of the same category with a comma.  Handle empty lists gracefully.\n",
        "            df.loc[index, category] = \", \".join(values) if values else \"\"\n",
        "\n",
        "\n",
        "    # --- 7. Save the modified DataFrame to a new CSV file ---\n",
        "    try:\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Successfully processed queries and saved results to '{output_csv}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving the output CSV: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# --- Example Usage ---\n",
        "# Create a dummy CSV file for testing\n",
        "data = {\n",
        "    'query': [\n",
        "        \"I want a Samsung 55-inch 4K smart TV.\",\n",
        "        \"Are there any noise-canceling headphones under $100?\",\n",
        "        \"My iPhone 13 screen is broken.\",\n",
        "        \"Looking for a cheap laptop with 16GB RAM.\",\n",
        "        \"Do you have the new Sony WH-1000XM5 headphones?\",\n",
        "        \"I need a black wireless mouse.\",\n",
        "        \"What's the best gaming laptop?\",\n",
        "        \"Is the Samsung Galaxy S23 waterproof?\",\n",
        "        \"My Dell XPS 15 is malfunctioning.\",\n",
        "        \"Show me 4k tv with Dolby vision\",\n",
        "        \"I want a black colored TV\",\n",
        "        \"which is the best tv under $2000\"\n",
        "    ]\n",
        "}\n",
        "queries_df = pd.DataFrame(data)\n",
        "queries_df.to_csv('queries.csv', index=False)\n",
        "\n",
        "\n",
        "# Run the attribute extraction\n",
        "extract_attributes('queries.csv', 'output.csv')\n",
        "\n",
        "# --- Inspect the output ---\n",
        "output_df = pd.read_csv('output.csv')\n",
        "print(output_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import re  # Import the regular expression module\n",
        "\n",
        "def extract_attributes(queries_csv, output_csv):\n",
        "    \"\"\"\n",
        "    Extracts key attributes from a CSV file of user queries using a transformer-based NER model\n",
        "    and significantly improved, rule-based post-processing.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(queries_csv)\n",
        "        if 'query' not in df.columns:\n",
        "            raise ValueError(\"The input CSV must contain a 'query' column.\")\n",
        "    except (FileNotFoundError, pd.errors.ParserError, ValueError) as e:\n",
        "        print(f\"Error loading or parsing CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 1. NER Pipeline (Still using dslim/bert-base-NER as a starting point) ---\n",
        "    try:\n",
        "        nlp = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading NER model: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 2. Improved Entity Categories (More Granular) ---\n",
        "    entity_categories = {\n",
        "        \"PRODUCT\": [],\n",
        "        \"BRAND\": [],\n",
        "        \"SPECIFICATION\": [],  # Expanded to handle more types\n",
        "        \"COLOR\": [],\n",
        "        \"FEATURE\": [],\n",
        "        \"PRICE\": [],\n",
        "        \"PROBLEM\": [],\n",
        "        \"RESOLUTION\": [],\n",
        "        \"SIZE\": [],\n",
        "        \"MODEL_NUMBER\": []  # New category for model numbers (e.g., WH-1000XM5)\n",
        "    }\n",
        "\n",
        "    # --- 3. Keyword Lists (Crucial for Post-Processing) ---\n",
        "    #  These lists are *essential* for improving accuracy.  Expand these lists!\n",
        "    product_keywords = [\"tv\", \"television\", \"laptop\", \"headphones\", \"phone\", \"smartphone\", \"tablet\", \"mouse\", \"keyboard\", \"monitor\", \"speaker\", \"camera\", \"printer\", \"router\", \"watch\", \"smartwatch\", \"earbuds\"]\n",
        "    feature_keywords = [\"noise-canceling\", \"wireless\", \"bluetooth\", \"waterproof\", \"voice control\", \"4k\", \"hdr\", \"oled\", \"qled\", \"touchscreen\", \"gaming\", \"portable\", \"dolby vision\", \"dolby atmos\"]\n",
        "    problem_keywords = [\"broken\", \"defective\", \"malfunctioning\", \"error\", \"issue\", \"problem\", \"not working\", \"doesn't work\", \"repair\", \"warranty\"]\n",
        "    resolution_keywords = [\"4k\", \"1080p\", \"720p\", \"hd\", \"full hd\", \"ultra hd\"]\n",
        "    size_keywords = [\"inch\", \"-inch\", \"''\"]  # Include variations\n",
        "    color_keywords = [\"black\", \"white\", \"silver\", \"gray\", \"red\", \"blue\", \"green\", \"gold\", \"pink\"]\n",
        "\n",
        "\n",
        "    # --- 4. Enhanced Processing Loop ---\n",
        "    for index, row in df.iterrows():\n",
        "        query = row['query']\n",
        "        try:\n",
        "            ner_results = nlp(query)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing query '{query}': {e}\")\n",
        "            continue\n",
        "\n",
        "        extracted_entities = {category: [] for category in entity_categories}\n",
        "        # Keep track of all entities found by the NER model, for use in rule-based extraction\n",
        "        all_ner_entities = [entity['word'] for entity in ner_results]\n",
        "\n",
        "\n",
        "        # --- 5. Rule-Based Extraction (The Key Improvement) ---\n",
        "\n",
        "        # 5.1. PRODUCT\n",
        "        for keyword in product_keywords:\n",
        "            if keyword in query.lower():  # Case-insensitive check\n",
        "                #  Check if the keyword is part of a larger word (e.g., \"headphones\" in \"over-ear headphones\")\n",
        "                match = re.search(r'\\b' + re.escape(keyword) + r'\\b', query.lower()) # Use regex for whole word\n",
        "                if match:\n",
        "                    # Extract the full product name (if possible)\n",
        "                    product_name = extract_full_product_name(query, match.start())\n",
        "                    extracted_entities[\"PRODUCT\"].append(product_name)\n",
        "\n",
        "        # 5.2. BRAND\n",
        "        for entity in ner_results:\n",
        "            if entity['entity_group'] == 'ORG':\n",
        "                extracted_entities[\"BRAND\"].append(entity['word'])\n",
        "\n",
        "        # 5.3. SPECIFICATION, RESOLUTION, SIZE (Combined and Improved)\n",
        "        # Use regular expressions to find specifications, resolutions, and sizes\n",
        "        spec_matches = re.findall(r'\\b(\\d+(?:\\.\\d+)?(?:gb|mb|tb|inch|hz))\\b', query.lower())  #e.g. 16GB, 256gb, 5.5inch, 60hz\n",
        "        for spec in spec_matches:\n",
        "            extracted_entities[\"SPECIFICATION\"].append(spec)\n",
        "\n",
        "        for keyword in resolution_keywords:\n",
        "            if keyword in query.lower():\n",
        "               extracted_entities[\"RESOLUTION\"].append(keyword)\n",
        "\n",
        "        for keyword in size_keywords:\n",
        "            size_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*' + re.escape(keyword), query.lower()) # Handles \"55 inch\" and \"55-inch\"\n",
        "            if size_match:\n",
        "                extracted_entities[\"SIZE\"].append(size_match.group(0))  # Add the whole match (e.g., \"55 inch\")\n",
        "\n",
        "\n",
        "        # 5.4. FEATURE\n",
        "        for keyword in feature_keywords:\n",
        "            if keyword in query.lower():\n",
        "                extracted_entities[\"FEATURE\"].append(keyword)\n",
        "\n",
        "        # 5.5. PRICE (Regex-Based)\n",
        "        price_match = re.search(r'(\\$?\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', query)  # Matches $, optional commas, and cents\n",
        "        if price_match:\n",
        "            price_text = price_match.group(1)\n",
        "            # Check for \"under\", \"over\", etc.\n",
        "            if \"under\" in query.lower() or \"less than\" in query.lower():\n",
        "                price_text = \"under \" + price_text\n",
        "            elif \"over\" in query.lower() or \"more than\" in query.lower():\n",
        "                price_text = \"over \" + price_text\n",
        "            extracted_entities[\"PRICE\"].append(price_text)\n",
        "\n",
        "\n",
        "        # 5.6. PROBLEM\n",
        "        for keyword in problem_keywords:\n",
        "            if keyword in query.lower():\n",
        "                extracted_entities[\"PROBLEM\"].append(keyword)\n",
        "\n",
        "        # 5.7. COLOR\n",
        "        for keyword in color_keywords:\n",
        "             if keyword in query.lower():\n",
        "                extracted_entities[\"COLOR\"].append(keyword)\n",
        "\n",
        "        #5.8 Model Number (using Regex)\n",
        "        model_match = re.search(r'\\b([A-Z0-9]{2,}-[A-Z0-9]{2,})\\b', query)  # Example: WH-1000XM5\n",
        "        if model_match:\n",
        "              extracted_entities[\"MODEL_NUMBER\"].append(model_match.group(1))\n",
        "\n",
        "\n",
        "        # --- 6. Add to DataFrame ---\n",
        "        for category, values in extracted_entities.items():\n",
        "            df.loc[index, category] = \", \".join(list(dict.fromkeys(values))) if values else \"\"  # Remove duplicates and join\n",
        "\n",
        "\n",
        "    try:\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Successfully processed queries and saved results to '{output_csv}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving output CSV: {e}\")\n",
        "\n",
        "\n",
        "def extract_full_product_name(query, keyword_start_index):\n",
        "    \"\"\"\n",
        "    Attempts to extract a more complete product name, going beyond just the keyword.\n",
        "    This is a heuristic and may need further refinement.\n",
        "    \"\"\"\n",
        "    # Expand to the left and right of the keyword, stopping at punctuation or the start/end of the string.\n",
        "    start = keyword_start_index\n",
        "    while start > 0 and query[start - 1].isalnum() or query[start-1] == ' ':\n",
        "        start -= 1\n",
        "\n",
        "    end = keyword_start_index\n",
        "    while end < len(query) and query[end].isalnum() or query[end] == ' ':\n",
        "        end += 1\n",
        "\n",
        "    return query[start:end].strip()\n",
        "\n",
        "\n",
        "# --- Example Usage (Using the same dummy data) ---\n",
        "data = {\n",
        "    'query': [\n",
        "        \"I want a Samsung 55-inch 4K smart TV.\",\n",
        "        \"Are there any noise-canceling headphones under $100?\",\n",
        "        \"My iPhone 13 screen is broken.\",\n",
        "        \"Looking for a cheap laptop with 16GB RAM.\",\n",
        "        \"Do you have the new Sony WH-1000XM5 headphones?\",\n",
        "        \"I need a black wireless mouse.\",\n",
        "        \"What's the best gaming laptop?\",\n",
        "        \"Is the Samsung Galaxy S23 waterproof?\",\n",
        "        \"My Dell XPS 15 is malfunctioning.\",\n",
        "        \"Show me 4k tv with Dolby vision\",\n",
        "        \"I want a black colored TV\",\n",
        "        \"which is the best tv under $2000\"\n",
        "    ]\n",
        "}\n",
        "queries_df = pd.DataFrame(data)\n",
        "queries_df.to_csv('queries.csv', index=False)\n",
        "\n",
        "extract_attributes('queries.csv', 'output.csv')\n",
        "output_df = pd.read_csv('output.csv')\n",
        "print(output_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "_HNthxDvwOJC",
        "outputId": "20241652-5578-4f64-d58e-8ed635d45e54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "string index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-551ffbc472f5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0mqueries_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'queries.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0mextract_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'queries.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0moutput_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-551ffbc472f5>\u001b[0m in \u001b[0;36mextract_attributes\u001b[0;34m(queries_csv, output_csv)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0;31m# Extract the full product name (if possible)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                     \u001b[0mproduct_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_full_product_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m                     \u001b[0mextracted_entities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PRODUCT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-551ffbc472f5>\u001b[0m in \u001b[0;36mextract_full_product_name\u001b[0;34m(query, keyword_start_index)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyword_start_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalnum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: string index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import re  # Import the regular expression module\n",
        "\n",
        "def extract_attributes(queries_csv, output_csv):\n",
        "    \"\"\"\n",
        "    Extracts key attributes from a CSV file of user queries using a transformer-based NER model\n",
        "    and significantly improved, rule-based post-processing.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(queries_csv)\n",
        "        if 'query' not in df.columns:\n",
        "            raise ValueError(\"The input CSV must contain a 'query' column.\")\n",
        "    except (FileNotFoundError, pd.errors.ParserError, ValueError) as e:\n",
        "        print(f\"Error loading or parsing CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 1. NER Pipeline (Still using dslim/bert-base-NER as a starting point) ---\n",
        "    try:\n",
        "        nlp = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading NER model: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 2. Improved Entity Categories (More Granular) ---\n",
        "    entity_categories = {\n",
        "        \"PRODUCT\": [],\n",
        "        \"BRAND\": [],\n",
        "        \"SPECIFICATION\": [],  # Expanded to handle more types\n",
        "        \"COLOR\": [],\n",
        "        \"FEATURE\": [],\n",
        "        \"PRICE\": [],\n",
        "        \"PROBLEM\": [],\n",
        "        \"RESOLUTION\": [],\n",
        "        \"SIZE\": [],\n",
        "        \"MODEL_NUMBER\": []  # New category for model numbers (e.g., WH-1000XM5)\n",
        "    }\n",
        "\n",
        "    # --- 3. Keyword Lists (Crucial for Post-Processing) ---\n",
        "    #  These lists are *essential* for improving accuracy.  Expand these lists!\n",
        "    product_keywords = [\"tv\", \"television\", \"laptop\", \"headphones\", \"phone\", \"smartphone\", \"tablet\", \"mouse\", \"keyboard\", \"monitor\", \"speaker\", \"camera\", \"printer\", \"router\", \"watch\", \"smartwatch\", \"earbuds\"]\n",
        "    feature_keywords = [\"noise-canceling\", \"wireless\", \"bluetooth\", \"waterproof\", \"voice control\", \"4k\", \"hdr\", \"oled\", \"qled\", \"touchscreen\", \"gaming\", \"portable\", \"dolby vision\", \"dolby atmos\"]\n",
        "    problem_keywords = [\"broken\", \"defective\", \"malfunctioning\", \"error\", \"issue\", \"problem\", \"not working\", \"doesn't work\", \"repair\", \"warranty\"]\n",
        "    resolution_keywords = [\"4k\", \"1080p\", \"720p\", \"hd\", \"full hd\", \"ultra hd\"]\n",
        "    size_keywords = [\"inch\", \"-inch\", \"''\"]  # Include variations\n",
        "    color_keywords = [\"black\", \"white\", \"silver\", \"gray\", \"red\", \"blue\", \"green\", \"gold\", \"pink\"]\n",
        "\n",
        "\n",
        "    # --- 4. Enhanced Processing Loop ---\n",
        "    for index, row in df.iterrows():\n",
        "        query = row['query']\n",
        "        try:\n",
        "            ner_results = nlp(query)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing query '{query}': {e}\")\n",
        "            continue\n",
        "\n",
        "        extracted_entities = {category: [] for category in entity_categories}\n",
        "        # Keep track of all entities found by the NER model, for use in rule-based extraction\n",
        "        all_ner_entities = [entity['word'] for entity in ner_results]\n",
        "\n",
        "\n",
        "        # --- 5. Rule-Based Extraction (The Key Improvement) ---\n",
        "\n",
        "        # 5.1. PRODUCT\n",
        "        for keyword in product_keywords:\n",
        "            if keyword in query.lower():  # Case-insensitive check\n",
        "                #  Check if the keyword is part of a larger word (e.g., \"headphones\" in \"over-ear headphones\")\n",
        "                match = re.search(r'\\b' + re.escape(keyword) + r'\\b', query.lower()) # Use regex for whole word\n",
        "                if match:\n",
        "                    # Extract the full product name (if possible)\n",
        "                    product_name = extract_full_product_name(query, match.start())\n",
        "                    extracted_entities[\"PRODUCT\"].append(product_name)\n",
        "\n",
        "        # 5.2. BRAND\n",
        "        for entity in ner_results:\n",
        "            if entity['entity_group'] == 'ORG':\n",
        "                extracted_entities[\"BRAND\"].append(entity['word'])\n",
        "\n",
        "        # 5.3. SPECIFICATION, RESOLUTION, SIZE (Combined and Improved)\n",
        "        # Use regular expressions to find specifications, resolutions, and sizes\n",
        "        spec_matches = re.findall(r'\\b(\\d+(?:\\.\\d+)?(?:gb|mb|tb|inch|hz))\\b', query.lower())  #e.g. 16GB, 256gb, 5.5inch, 60hz\n",
        "        for spec in spec_matches:\n",
        "            extracted_entities[\"SPECIFICATION\"].append(spec)\n",
        "\n",
        "        for keyword in resolution_keywords:\n",
        "            if keyword in query.lower():\n",
        "               extracted_entities[\"RESOLUTION\"].append(keyword)\n",
        "\n",
        "        for keyword in size_keywords:\n",
        "            size_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*' + re.escape(keyword), query.lower()) # Handles \"55 inch\" and \"55-inch\"\n",
        "            if size_match:\n",
        "                extracted_entities[\"SIZE\"].append(size_match.group(0))  # Add the whole match (e.g., \"55 inch\")\n",
        "\n",
        "\n",
        "        # 5.4. FEATURE\n",
        "        for keyword in feature_keywords:\n",
        "            if keyword in query.lower():\n",
        "                extracted_entities[\"FEATURE\"].append(keyword)\n",
        "\n",
        "        # 5.5. PRICE (Regex-Based)\n",
        "        price_match = re.search(r'(\\$?\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', query)  # Matches $, optional commas, and cents\n",
        "        if price_match:\n",
        "            price_text = price_match.group(1)\n",
        "            # Check for \"under\", \"over\", etc.\n",
        "            if \"under\" in query.lower() or \"less than\" in query.lower():\n",
        "                price_text = \"under \" + price_text\n",
        "            elif \"over\" in query.lower() or \"more than\" in query.lower():\n",
        "                price_text = \"over \" + price_text\n",
        "            extracted_entities[\"PRICE\"].append(price_text)\n",
        "\n",
        "\n",
        "        # 5.6. PROBLEM\n",
        "        for keyword in problem_keywords:\n",
        "            if keyword in query.lower():\n",
        "                extracted_entities[\"PROBLEM\"].append(keyword)\n",
        "\n",
        "        # 5.7. COLOR\n",
        "        for keyword in color_keywords:\n",
        "             if keyword in query.lower():\n",
        "                extracted_entities[\"COLOR\"].append(keyword)\n",
        "\n",
        "        #5.8 Model Number (using Regex)\n",
        "        model_match = re.search(r'\\b([A-Z0-9]{2,}-[A-Z0-9]{2,})\\b', query)  # Example: WH-1000XM5\n",
        "        if model_match:\n",
        "              extracted_entities[\"MODEL_NUMBER\"].append(model_match.group(1))\n",
        "\n",
        "\n",
        "        # --- 6. Add to DataFrame ---\n",
        "        for category, values in extracted_entities.items():\n",
        "            df.loc[index, category] = \", \".join(list(dict.fromkeys(values))) if values else \"\"  # Remove duplicates and join\n",
        "\n",
        "\n",
        "    try:\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Successfully processed queries and saved results to '{output_csv}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving output CSV: {e}\")\n",
        "\n",
        "\n",
        "def extract_full_product_name(query, keyword_start_index):\n",
        "    \"\"\"\n",
        "    Extracts a more complete product name, handling edge cases and variations.\n",
        "    \"\"\"\n",
        "    # 1. Lowercase the query for case-insensitive matching.\n",
        "    query = query.lower()\n",
        "    keyword_start_index = query.find(query[keyword_start_index:].lower())\n",
        "\n",
        "\n",
        "    # 2. Find the start of the potential product name (moving left).\n",
        "    start = keyword_start_index\n",
        "    while start > 0 and (query[start - 1].isalnum() or query[start - 1] in \" -\"):\n",
        "        start -= 1\n",
        "\n",
        "    # 3. Find the end of the potential product name (moving right).\n",
        "    end = keyword_start_index\n",
        "    # Find length of the matched word/keyword\n",
        "    len_keyword = 0\n",
        "    while end < len(query) and (query[end].isalnum() or query[end] in \" -\"):\n",
        "        len_keyword = len_keyword + 1\n",
        "        end = end + 1\n",
        "\n",
        "    # 4. Extract the product name and clean it up.\n",
        "    product_name = query[start : keyword_start_index + len_keyword]\n",
        "\n",
        "     #Remove extra spaces using a regular expression:\n",
        "    product_name = re.sub(r\"\\s+\", \" \", product_name).strip() # Replace multiple spaces with one\n",
        "\n",
        "    return product_name\n",
        "\n",
        "\n",
        "\n",
        "# --- Example Usage (Using the same dummy data + edge case test) ---\n",
        "data = {\n",
        "    'query': [\n",
        "        \"I want a Samsung 55-inch 4K smart TV.\",\n",
        "        \"Are there any noise-canceling headphones under $100?\",\n",
        "        \"My iPhone 13 screen is broken.\",\n",
        "        \"Looking for a cheap laptop with 16GB RAM.\",\n",
        "        \"Do you have the new Sony WH-1000XM5 headphones?\",\n",
        "        \"I need a black wireless mouse.\",\n",
        "        \"What's the best gaming laptop?\",\n",
        "        \"Is the Samsung Galaxy S23 waterproof?\",\n",
        "        \"My Dell XPS 15 is malfunctioning.\",\n",
        "        \"Show me 4k tv with Dolby vision\",\n",
        "        \"I want a black colored TV\",\n",
        "        \"which is the best tv under $2000\",\n",
        "        \"I want a tv\"  # Edge case test\n",
        "    ]\n",
        "}\n",
        "queries_df = pd.DataFrame(data)\n",
        "queries_df.to_csv('queries.csv', index=False)\n",
        "\n",
        "extract_attributes('queries.csv', 'output.csv')\n",
        "output_df = pd.read_csv('output.csv')\n",
        "print(output_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrMxM9Snx8I4",
        "outputId": "e798cf88-53c2-41db-836d-582266bf3041"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully processed queries and saved results to 'output.csv'\n",
            "                                                query  \\\n",
            "0               I want a Samsung 55-inch 4K smart TV.   \n",
            "1   Are there any noise-canceling headphones under...   \n",
            "2                      My iPhone 13 screen is broken.   \n",
            "3           Looking for a cheap laptop with 16GB RAM.   \n",
            "4     Do you have the new Sony WH-1000XM5 headphones?   \n",
            "5                      I need a black wireless mouse.   \n",
            "6                      What's the best gaming laptop?   \n",
            "7               Is the Samsung Galaxy S23 waterproof?   \n",
            "8                   My Dell XPS 15 is malfunctioning.   \n",
            "9                     Show me 4k tv with Dolby vision   \n",
            "10                          I want a black colored TV   \n",
            "11                   which is the best tv under $2000   \n",
            "12                                        I want a tv   \n",
            "\n",
            "                                           PRODUCT    BRAND SPECIFICATION  \\\n",
            "0             i want a samsung 55-inch 4k smart tv  Samsung           NaN   \n",
            "1   are there any noise-canceling headphones under      NaN           NaN   \n",
            "2                                              NaN      NaN           NaN   \n",
            "3         looking for a cheap laptop with 16gb ram      NaN          16gb   \n",
            "4   do you have the new sony wh-1000xm5 headphones      NaN           NaN   \n",
            "5                    i need a black wireless mouse      NaN           NaN   \n",
            "6                         s the best gaming laptop      NaN           NaN   \n",
            "7                                              NaN      NaN           NaN   \n",
            "8                                              NaN      NaN           NaN   \n",
            "9                  show me 4k tv with dolby vision      NaN           NaN   \n",
            "10                       i want a black colored tv      NaN           NaN   \n",
            "11                      which is the best tv under      NaN           NaN   \n",
            "12                                     i want a tv      NaN           NaN   \n",
            "\n",
            "         COLOR           FEATURE        PRICE         PROBLEM RESOLUTION  \\\n",
            "0          NaN                4k           55             NaN         4k   \n",
            "1          NaN   noise-canceling   under $100             NaN        NaN   \n",
            "2          NaN               NaN           13          broken        NaN   \n",
            "3          NaN               NaN           16             NaN        NaN   \n",
            "4          NaN               NaN         1000             NaN        NaN   \n",
            "5        black          wireless          NaN             NaN        NaN   \n",
            "6          NaN            gaming          NaN             NaN        NaN   \n",
            "7          NaN        waterproof           23             NaN        NaN   \n",
            "8          NaN               NaN           15  malfunctioning        NaN   \n",
            "9          NaN  4k, dolby vision            4             NaN         4k   \n",
            "10  black, red               NaN          NaN             NaN        NaN   \n",
            "11         NaN               NaN  under $2000             NaN        NaN   \n",
            "12         NaN               NaN          NaN             NaN        NaN   \n",
            "\n",
            "       SIZE MODEL_NUMBER  \n",
            "0   55-inch          NaN  \n",
            "1       NaN          NaN  \n",
            "2       NaN          NaN  \n",
            "3       NaN          NaN  \n",
            "4       NaN   WH-1000XM5  \n",
            "5       NaN          NaN  \n",
            "6       NaN          NaN  \n",
            "7       NaN          NaN  \n",
            "8       NaN          NaN  \n",
            "9       NaN          NaN  \n",
            "10      NaN          NaN  \n",
            "11      NaN          NaN  \n",
            "12      NaN          NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gliner import GLiNER\n",
        "from typing import List\n",
        "\n",
        "# Initialize GLiNER (requires torch)\n",
        "model = GLiNER.from_pretrained(\"urchade/gliner_base\")\n",
        "\n",
        "# Define your entity categories with example prompts\n",
        "entity_categories = {\n",
        "    \"PRODUCT\": \"electrical device or product name\",\n",
        "    \"BRAND\": \"company or manufacturer name\",\n",
        "    \"SPECIFICATION\": \"technical specification or measurement\",\n",
        "    \"COLOR\": \"color description\",\n",
        "    \"FEATURE\": \"product feature or capability\",\n",
        "    \"PRICE\": \"price or monetary value\",\n",
        "    \"PROBLEM\": \"product issue or defect\",\n",
        "    \"RESOLUTION\": \"solution or resolution action\",\n",
        "    \"SIZE\": \"size dimension\",\n",
        "    \"MODEL_NUMBER\": \"alphanumeric product code\"\n",
        "}\n",
        "\n",
        "def gliner_extract(text: str, threshold: float = 0.5) -> dict:\n",
        "    entities = model.predict_entities(text, [v for v in entity_categories.values()], threshold=threshold)\n",
        "\n",
        "    result = {k: [] for k in entity_categories.keys()}\n",
        "    for entity in entities:\n",
        "        for cat, prompt in entity_categories.items():\n",
        "            if entity['label'] == prompt:\n",
        "                result[cat].append(entity['text'])\n",
        "    return {k: \", \".join(v) for k, v in result.items()}\n",
        "\n",
        "def process_csv(input_path, output_path):\n",
        "    df = pd.read_csv(input_path)\n",
        "    df = df.join(df['query'].apply(lambda x: pd.Series(gliner_extract(x))))\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_csv(\"input_queries.csv\", \"output_entities.csv\")"
      ],
      "metadata": {
        "id": "TjTPDcYbylUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'query': [\n",
        "        # Samsung TVs\n",
        "        \"Is the Samsung QN90B 65-inch 4K Neo QLED TV available in black?\",\n",
        "        \"I'm looking for a 55-inch Samsung TV with 4K resolution under $1000.\",\n",
        "        \"Does the Samsung Frame TV come in 43-inch and have art mode?\",\n",
        "        \"My Samsung Q80T 75-inch TV has a flickering screen.  What can I do?\",\n",
        "        \"What's the price of a Samsung 8K QLED TV, specifically the QN900B?\",\n",
        "        \"I need a curved Samsung TV, around 50 inches, with good sound.\",\n",
        "        \"Is the Samsung S95B OLED TV good for gaming?\",\n",
        "        \"Looking for a 32-inch Samsung smart TV, preferably white, for my kitchen.\",\n",
        "        \"Does Samsung make any outdoor TVs with weatherproofing?\",\n",
        "        \"My old Samsung TV remote is broken. Where can I get a replacement?\",\n",
        "        \"Are there any Samsung TVs with built-in Alexa?\",\n",
        "        \"I want a Samsung TV with Dolby Atmos and a 120Hz refresh rate.\",\n",
        "        \"Compare the Samsung QN85B and QN90B 50-inch models.\",\n",
        "        \"What's the best 75-inch Samsung TV for a bright room?\",\n",
        "        \"Is there a Samsung TV that supports both FreeSync and G-Sync?\",\n",
        "\n",
        "        # Samsung Phones\n",
        "        \"Does the Samsung Galaxy S23 Ultra come in green and with 512GB storage?\",\n",
        "        \"I want a Samsung phone with a good camera for under $800.\",\n",
        "        \"My Samsung Galaxy Z Fold 4 screen is cracked. Is it covered by warranty?\",\n",
        "        \"What's the battery life like on the Samsung Galaxy A54?\",\n",
        "        \"Is the Samsung Galaxy S22 still a good phone in 2024?\",\n",
        "        \"I need a rugged Samsung phone that's waterproof and dustproof.\",\n",
        "        \"Does the Samsung Galaxy S23 have expandable storage?\",\n",
        "        \"I dropped my Samsung phone and the screen is black.  Can it be repaired?\",\n",
        "        \"What's the cheapest Samsung phone with 5G?\",\n",
        "        \"Compare the camera on the Samsung Galaxy S23+ and the S23 Ultra.\",\n",
        "        \"Is there a Samsung phone with a stylus?\",\n",
        "        \"My Samsung Galaxy Note 20 is running slow. How can I speed it up?\",\n",
        "        \"Which Samsung phone has the best zoom capabilities?\",\n",
        "        \"Does the Samsung Galaxy Z Flip 5 have wireless charging?\",\n",
        "        \"I want a small Samsung phone, something like the Galaxy S22.\",\n",
        "\n",
        "        # Samsung Headphones & Earbuds\n",
        "        \"Are the Samsung Galaxy Buds 2 Pro noise-canceling?\",\n",
        "        \"I lost one of my Samsung Galaxy Buds. Can I buy a single replacement?\",\n",
        "        \"What's the difference between the Samsung Galaxy Buds 2 and Buds Pro?\",\n",
        "        \"Do the Samsung Galaxy Buds FE have good bass?\",\n",
        "        \"Are Samsung earbuds compatible with iPhones?\",\n",
        "        \"My Samsung headphones won't connect to my laptop.  What should I do?\",\n",
        "        \"How long does the battery last on the Samsung Galaxy Buds Live?\",\n",
        "        \"I need waterproof earbuds for swimming. Does Samsung make any?\",\n",
        "        \"Are there any Samsung headphones with a built-in microphone?\",\n",
        "        \"What's the best Samsung earbuds for working out?\",\n",
        "\n",
        "        # Samsung Tablets\n",
        "        \"Does the Samsung Galaxy Tab S9 Ultra have a 120Hz display?\",\n",
        "        \"I want a Samsung tablet with an S Pen for under $500.\",\n",
        "        \"My Samsung Galaxy Tab S8 screen is unresponsive. How do I fix it?\",\n",
        "        \"Is the Samsung Galaxy Tab A8 good for reading ebooks?\",\n",
        "        \"What's the largest screen size available for a Samsung tablet?\",\n",
        "        \"I need a Samsung tablet with long battery life for travel.\",\n",
        "        \"Does the Samsung Galaxy Tab S9 FE come in different colors?\",\n",
        "        \"My Samsung tablet is frozen. How do I restart it?\",\n",
        "        \"What's the best Samsung tablet for drawing and note-taking?\",\n",
        "        \"Can I use a Samsung tablet as a second screen for my laptop?\",\n",
        "        \"Is the Samsung Galaxy Tab Active Pro ruggedized?\",\n",
        "\n",
        "        # Samsung Watches\n",
        "        \"Does the Samsung Galaxy Watch 6 Classic have ECG and blood pressure monitoring?\",\n",
        "        \"I want a Samsung watch with LTE connectivity.\",\n",
        "        \"My Samsung Galaxy Watch 5 won't charge.  What's wrong?\",\n",
        "        \"Is the Samsung Galaxy Watch 4 still a good buy?\",\n",
        "        \"What's the battery life of the Samsung Galaxy Watch 6?\",\n",
        "        \"I need a Samsung watch that's good for tracking fitness.\",\n",
        "        \"Does the Samsung Galaxy Watch have fall detection?\",\n",
        "        \"My Samsung watch band broke. Where can I get a new one?\",\n",
        "        \"What's the best Samsung watch for sleep tracking?\",\n",
        "        \"Can I make calls from a Samsung Galaxy Watch?\",\n",
        "\n",
        "        # Combinations & General Queries\n",
        "        \"Looking for a Samsung soundbar with Dolby Atmos and a wireless subwoofer.\",\n",
        "        \"Do you have any Samsung appliances, like refrigerators or washing machines?\",  #(Out of scope, but good to include for testing)\n",
        "        \"What are the latest Samsung product releases?\",\n",
        "        \"I need a Samsung charger for my phone and watch.\",\n",
        "        \"Where can I find the nearest Samsung service center?\",\n",
        "        \"Are there any current promotions on Samsung products?\",\n",
        "        \"I want to trade in my old Samsung phone for a new one.\",\n",
        "        \"Do you sell refurbished Samsung products?\",\n",
        "        \"What's the warranty on Samsung products?\",\n",
        "        \"I'm having trouble setting up my Samsung SmartThings hub.\",\n",
        "        \"Can I control my Samsung TV with my phone?\",\n",
        "        \"I want a Samsung monitor for gaming with a high refresh rate.\",\n",
        "        \"Does Samsung offer student discounts?\",\n",
        "\n",
        "        # More specific combinations\n",
        "        \"Looking for a black Samsung Galaxy S23 Ultra with 256GB and the S Pen.\",\n",
        "        \"Need a 65-inch Samsung QLED TV with 4K resolution and HDMI 2.1.\",\n",
        "        \"My Samsung Galaxy Buds Pro case is lost; can I buy a replacement?\",\n",
        "        \"Is there a silver Samsung Galaxy Watch 6 with a rotating bezel?\",\n",
        "        \"Want a Samsung Galaxy Tab S9+ with 5G and the keyboard cover.\",\n",
        "        \"Looking for a Samsung phone with a really good camera, over 50MP.\",\n",
        "        \"Need a rugged Samsung tablet that can withstand drops and water.\",\n",
        "        \"I want a Samsung TV that's specifically designed for gaming.\",\n",
        "        \"Does Samsung make any noise-canceling headphones that are also wireless?\",\n",
        "        \"My Samsung phone screen is cracked, but it's still under warranty.\",\n",
        "        \"Is there a Samsung watch that can track my swimming workouts?\",\n",
        "        \"Looking for a large Samsung tablet, at least 12 inches, for drawing.\",\n",
        "        \"I want a Samsung phone that has a really long battery life, over 4000mAh.\",\n",
        "        \"Does Samsung have any TVs with built-in voice assistants like Bixby?\",\n",
        "        \"My Samsung earbuds keep disconnecting from my phone; is this a common problem?\",\n",
        "\n",
        "        # More edge cases / problem scenarios\n",
        "        \"My brand new Samsung QN95B TV has dead pixels. What should I do?\",\n",
        "        \"The Samsung Galaxy Z Flip 4 hinge is making a creaking noise.\",\n",
        "        \"I can't update the software on my Samsung Galaxy Watch 5.\",\n",
        "        \"My Samsung tablet is stuck in a boot loop.\",\n",
        "        \"The battery on my Samsung phone drains very quickly, even when I'm not using it.\",\n",
        "        \"My Samsung TV remote is unresponsive, even with new batteries.\",\n",
        "        \"I accidentally spilled water on my Samsung laptop. What should I do?\",  #(Laptop is out of scope, but good for testing robustness)\n",
        "        \"The charging port on my Samsung phone is loose.\",\n",
        "        \"My Samsung soundbar won't connect to my TV via Bluetooth.\",\n",
        "        \"I forgot the password to my Samsung tablet.\",\n",
        "        \"My Samsung Galaxy Buds Pro are causing ear irritation.\",\n",
        "        \"The screen on my Samsung watch is scratched. Can it be replaced?\",\n",
        "        \"I'm experiencing audio lag when using my Samsung headphones with my TV.\",\n",
        "        \"My Samsung phone is overheating when I play games.\",\n",
        "        \"The fingerprint sensor on my Samsung phone isn't working reliably.\",\n",
        "\n",
        "        # Asking for comparisons\n",
        "        \"What's the main difference between the Samsung Galaxy S23 and the Google Pixel 7?\",  #(Comparison with another brand)\n",
        "        \"Compare the Samsung QN90B and the LG C2 OLED TVs.\" ,  #(Comparison with another brand)\n",
        "        \"Which is better for gaming, the Samsung Galaxy S23 Ultra or the iPhone 14 Pro Max?\", #(Comparison with another brand)\n",
        "        \"Should I get the Samsung Galaxy Buds 2 Pro or the Apple AirPods Pro 2?\", #(Comparison with another brand)\n",
        "        \"What are the pros and cons of the Samsung Galaxy Watch 6 vs. the Watch 5?\",\n",
        "        \"How does the Samsung Galaxy Tab S9 compare to the iPad Air?\" #(Comparison with another brand)\n",
        "\n",
        "    ]\n",
        "}\n",
        "\n",
        "queries_df = pd.DataFrame(data)\n",
        "print(f\"Number of queries generated: {len(queries_df)}\")\n",
        "queries_df.to_csv('samsung_queries_100.csv', index=False)\n",
        "\n",
        "output_df = pd.read_csv('samsung_queries_100.csv')\n",
        "print(output_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWqyfv7M--xx",
        "outputId": "50d58889-f2d8-4658-e237-87f0458faf86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of queries generated: 110\n",
            "                                                 query\n",
            "0    Is the Samsung QN90B 65-inch 4K Neo QLED TV av...\n",
            "1    I'm looking for a 55-inch Samsung TV with 4K r...\n",
            "2    Does the Samsung Frame TV come in 43-inch and ...\n",
            "3    My Samsung Q80T 75-inch TV has a flickering sc...\n",
            "4    What's the price of a Samsung 8K QLED TV, spec...\n",
            "..                                                 ...\n",
            "105  Compare the Samsung QN90B and the LG C2 OLED TVs.\n",
            "106  Which is better for gaming, the Samsung Galaxy...\n",
            "107  Should I get the Samsung Galaxy Buds 2 Pro or ...\n",
            "108  What are the pros and cons of the Samsung Gala...\n",
            "109  How does the Samsung Galaxy Tab S9 compare to ...\n",
            "\n",
            "[110 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. What is the best Samsung smartphone PRODUCT with FEATURE wireless charging under $500?\n",
        "# 2. Compare Samsung Galaxy S23 MODEL_NUMBER specifications across different COLOR options\n",
        "# 3. How to resolve PROBLEM of battery drain on Samsung NOTE PRODUCT\n",
        "# 4. Samsung TV BRAND comparison by SIZE and PRICE range\n",
        "# 5. What SPECIFICATION makes Samsung A53 MODEL_NUMBER superior to competitors?\n",
        "# 6. Cheapest Samsung smartphone with FEATURE 5G and under $300 PRICE\n",
        "# 7. Samsung refrigerator COLOR options for modern kitchen design\n",
        "# 8. How to fix RESOLUTION issues with Samsung PRODUCT display\n",
        "# 9. Best Samsung laptop with highest RAM SPECIFICATION\n",
        "# 10. Samsung BRAND washing machine models with energy-efficient FEATURE\n",
        "# 11. Compare Samsung smartphone PRICE across different MODEL_NUMBER variants\n",
        "# 12. Which Samsung PRODUCT has the best camera SPECIFICATION?\n",
        "# 13. Troubleshoot PROBLEM with Samsung tablet not turning on\n",
        "# 14. Samsung smart TV SIZE recommendations for living rooms\n",
        "# 15. Most affordable Samsung BRAND smartphone with premium FEATURE\n",
        "# 16. Samsung Galaxy Z PRODUCT series COLOR availability\n",
        "# 17. Detailed SPECIFICATION of Samsung S22 MODEL_NUMBER camera system\n",
        "# 18. How to resolve RESOLUTION problems on Samsung monitor\n",
        "# 19. Samsung laptop PRICE range for professional users\n",
        "# 20. Best Samsung refrigerator FEATURE for large families\n",
        "# 21. Samsung smartphone COLOR options for professional settings\n",
        "# 22. What SPECIFICATION differentiates Samsung A-series MODEL_NUMBER?\n",
        "# 23. Troubleshoot battery PROBLEM on Samsung Galaxy devices\n",
        "# 24. Samsung TV BRAND reliability comparison\n",
        "# 25. Most compact Samsung laptop with powerful SPECIFICATION\n",
        "# 26. Samsung smartphone PRODUCT with longest battery life\n",
        "# 27. Compare Samsung tablet PRICE across different MODEL_NUMBER\n",
        "# 28. How to fix audio RESOLUTION on Samsung smart TV\n",
        "# 29. Samsung smartphone FEATURE comparison for photography enthusiasts\n",
        "# 30. Best Samsung BRAND appliance for small apartments\n",
        "# 31. Samsung Galaxy Z PRODUCT folding mechanism SPECIFICATION\n",
        "# 32. Affordable Samsung smartphone COLOR options\n",
        "# 33. Troubleshoot PROBLEM with Samsung wireless earbuds\n",
        "# 34. Samsung monitor SIZE recommendations for graphic designers\n",
        "# 35. Which Samsung PRODUCT offers best value for money?\n",
        "# 36. Samsung smartphone MODEL_NUMBER with water resistance FEATURE\n",
        "# 37. Compare Samsung TV PRICE across different SIZE ranges\n",
        "# 38. How to resolve display RESOLUTION issues on Samsung devices\n",
        "# 39. Samsung laptop SPECIFICATION for gaming performance\n",
        "# 40. Best Samsung refrigerator COLOR for minimalist kitchens\n",
        "# 41. Samsung Galaxy S PRODUCT line camera SPECIFICATION breakdown\n",
        "# 42. Troubleshoot charging PROBLEM on Samsung smartphones\n",
        "# 43. Samsung smart TV FEATURE comparison for streaming\n",
        "# 44. Most lightweight Samsung laptop MODEL_NUMBER\n",
        "# 45. Samsung smartphone BRAND market positioning analysis\n",
        "# 46. Compare Samsung tablet SPECIFICATION across different models\n",
        "# 47. How to fix connectivity RESOLUTION on Samsung devices\n",
        "# 48. Samsung refrigerator PRICE range for budget buyers\n",
        "# 49. Best Samsung PRODUCT for mobile photography\n",
        "# 50. Samsung Galaxy NOTE COLOR options for professionals\n",
        "# 51. Troubleshoot software PROBLEM on Samsung smart devices\n",
        "# 52. Samsung monitor SPECIFICATION for video editing\n",
        "# 53. Affordable Samsung smartphone FEATURE comparison\n",
        "# 54. Compare Samsung TV MODEL_NUMBER across different PRICE points\n",
        "# 55. How to resolve storage RESOLUTION on Samsung tablets\n",
        "# 56. Samsung laptop BRAND performance benchmarks\n",
        "# 57. Best Samsung refrigerator FEATURE for energy efficiency\n",
        "# 58. Samsung smartphone PRODUCT durability SPECIFICATION\n",
        "# 59. Troubleshoot Bluetooth PROBLEM on Samsung accessories\n",
        "# 60. Samsung smart TV SIZE guide for different room dimensions\n",
        "# 61. Compare Samsung Galaxy Z PRODUCT series SPECIFICATION\n",
        "# 62. Samsung smartphone COLOR trends for 2024\n",
        "# 63. How to fix camera RESOLUTION issues on Samsung devices\n",
        "# 64. Samsung laptop PRICE comparison for students\n",
        "# 65. Best Samsung BRAND wearable technology\n",
        "# 66. Samsung refrigerator MODEL_NUMBER with smart home FEATURE\n",
        "# 67. Troubleshoot battery charging PROBLEM on Samsung devices\n",
        "# 68. Samsung monitor COLOR calibration guide\n",
        "# 69. Compare Samsung smartphone SPECIFICATION across price ranges\n",
        "# 70. How to resolve network RESOLUTION on Samsung tablets\n",
        "# 71. Samsung TV PRODUCT lineup with best picture quality\n",
        "# 72. Best Samsung laptop for professional SPECIFICATION\n",
        "# 73. Troubleshoot audio PROBLEM on Samsung smart TV\n",
        "# 74. Samsung smartphone COLOR psychology and design\n",
        "# 75. Compare Samsung refrigerator SIZE for different kitchen layouts\n",
        "# 76. How to fix software update RESOLUTION on Samsung devices\n",
        "# 77. Samsung Galaxy A PRODUCT series budget SPECIFICATION\n",
        "# 78. Best Samsung monitor FEATURE for remote work\n",
        "# 79. Troubleshoot Wi-Fi PROBLEM on Samsung smart home devices\n",
        "# 80. Samsung smartphone MODEL_NUMBER battery performance comparison\n",
        "# 81. Compare Samsung TV BRAND reliability ratings\n",
        "# 82. How to resolve display COLOR calibration issues\n",
        "# 83. Samsung laptop SPECIFICATION for content creators\n",
        "# 84. Best Samsung refrigerator with smart home FEATURE\n",
        "# 85. Troubleshoot connectivity PROBLEM on Samsung wireless devices\n",
        "# 86. Samsung smartphone PRODUCT camera low-light SPECIFICATION\n",
        "# 87. Compare Samsung tablet SIZE for portability\n",
        "# 88. How to fix charging PORT RESOLUTION on Samsung devices\n",
        "# 89. Samsung smart TV PRICE range for budget buyers\n",
        "# 90. Best Samsung laptop COLOR options for professionals\n",
        "# 91. Troubleshoot software compatibility PROBLEM on Samsung devices\n",
        "# 92. Samsung smartphone FEATURE comparison for battery life\n",
        "# 93. Compare Samsung monitor SPECIFICATION for gaming\n",
        "# 94. How to resolve audio output RESOLUTION on Samsung TV\n",
        "# 95. Samsung refrigerator MODEL_NUMBER energy efficiency ratings\n",
        "# 96. Best Samsung PRODUCT for mobile gaming\n",
        "# 97. Troubleshoot Bluetooth pairing PROBLEM on Samsung accessories\n",
        "# 98. Samsung smartphone COLOR trends in professional market\n",
        "# 99. Compare Samsung TV SIZE recommendations\n",
        "# 100. How to resolve system performance RESOLUTION on Samsung devices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "quzWJ1HN-_eA",
        "outputId": "33ea27d3-cdea-420f-a765-5a660d7315e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-7-7344f275c6a0>, line 6)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-7344f275c6a0>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    6. Cheapest Samsung smartphone with FEATURE 5G and under $300 PRICE\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXHdNGYiAMTO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}