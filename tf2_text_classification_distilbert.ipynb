{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_text_classification_distilbert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Deep_learning_experiments/blob/master/tf2_text_classification_distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgfHNcOPbOk3",
        "colab_type": "text"
      },
      "source": [
        "### A Simplied Interface to Text Classification With Hugging Face Transformers in TensorFlow Using [ktrain](https://github.com/amaiya/ktrain)\n",
        "\n",
        "*ktrain* requires TensorFlow 2.\n",
        "\n",
        "Associated [Blog](https://towardsdatascience.com/text-classification-with-hugging-face-transformers-in-tensorflow-2-without-tears-ee50e4f3e7ed)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDBNS4iNXuUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -q tensorflow_gpu>=2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAA46kq4X0C_",
        "colab_type": "code",
        "outputId": "98caeb06-143c-49e2-dc95-06d2deec438f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iitDk1j6bpY3",
        "colab_type": "text"
      },
      "source": [
        "We then need to install *ktrain* library using pip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAYBZG2SX4nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -q ktrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdk5lPu3bxze",
        "colab_type": "text"
      },
      "source": [
        "### Load a Dataset Into Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rSbSqApYPBe",
        "colab_type": "code",
        "outputId": "d1566383-56c9-4fa6-ebcf-82a29a7abb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "             'comp.graphics', 'sci.med']\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "train_b = fetch_20newsgroups(subset='train',\n",
        "   categories=categories, shuffle=True, random_state=42)\n",
        "test_b = fetch_20newsgroups(subset='test',\n",
        "   categories=categories, shuffle=True, random_state=42)\n",
        "\n",
        "print('size of training set: %s' % (len(train_b['data'])))\n",
        "print('size of validation set: %s' % (len(test_b['data'])))\n",
        "print('classes: %s' % (train_b.target_names))\n",
        "\n",
        "x_train = train_b.data\n",
        "y_train = train_b.target\n",
        "x_test = test_b.data\n",
        "y_test = test_b.target"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "size of training set: 2257\n",
            "size of validation set: 1502\n",
            "classes: ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe5xxVPrb4IO",
        "colab_type": "text"
      },
      "source": [
        "## STEP 1:  Preprocess Data and Create a Transformer Model\n",
        "\n",
        "We will use [DistilBERT](https://arxiv.org/abs/1910.01108)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5phkVc7ZYnue",
        "colab_type": "code",
        "outputId": "03cb0eb7-edbf-43f1-e328-33947923db0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "t = text.Transformer(MODEL_NAME, maxlen=500, classes=train_b.target_names)\n",
        "trn = t.preprocess_train(x_train, y_train)\n",
        "val = t.preprocess_test(x_test, y_test)\n",
        "model = t.get_classifier()\n",
        "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Keras version: 2.2.4-tf\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4sGPJgOcBTd",
        "colab_type": "text"
      },
      "source": [
        "## STEP 2:  Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_nH_F9yYvCd",
        "colab_type": "code",
        "outputId": "6316127d-a7b0-4b5b-e911-8e97d9174c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "learner.fit_onecycle(5e-5, 4)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 5e-05...\n",
            "Train for 377 steps, validate for 251 steps\n",
            "Epoch 1/4\n",
            "377/377 [==============================] - 180s 477ms/step - loss: 0.5714 - accuracy: 0.8285 - val_loss: 0.1747 - val_accuracy: 0.9441\n",
            "Epoch 2/4\n",
            "377/377 [==============================] - 178s 473ms/step - loss: 0.1623 - accuracy: 0.9508 - val_loss: 0.1937 - val_accuracy: 0.9387\n",
            "Epoch 3/4\n",
            "377/377 [==============================] - 178s 473ms/step - loss: 0.0640 - accuracy: 0.9827 - val_loss: 0.2094 - val_accuracy: 0.9401\n",
            "Epoch 4/4\n",
            "377/377 [==============================] - 178s 473ms/step - loss: 0.0231 - accuracy: 0.9947 - val_loss: 0.1916 - val_accuracy: 0.9607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce3a669b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho6eSo9IcI3_",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3: Evaluate and Inspect the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvcxCvLOcOje",
        "colab_type": "code",
        "outputId": "7c89e8d6-4b86-4c6a-a9b9-cee7f94344c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "learner.validate(class_names=t.get_classes())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.91      0.97      0.94       319\n",
            "         comp.graphics       0.97      0.95      0.96       389\n",
            "               sci.med       0.98      0.96      0.97       396\n",
            "soc.religion.christian       0.98      0.96      0.97       398\n",
            "\n",
            "              accuracy                           0.96      1502\n",
            "             macro avg       0.96      0.96      0.96      1502\n",
            "          weighted avg       0.96      0.96      0.96      1502\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[309,   2,   2,   6],\n",
              "       [ 14, 370,   4,   1],\n",
              "       [  6,   7, 381,   2],\n",
              "       [ 12,   2,   1, 383]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhG3fPtPcVKe",
        "colab_type": "text"
      },
      "source": [
        "Let's examine the validation example about which we were the most wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCABLebacTWM",
        "colab_type": "code",
        "outputId": "c82fb8c9-2f3c-4e48-d964-5a5be71a45bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "learner.view_top_losses(n=1, preproc=t)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "id:146 | loss:7.57 | true:comp.graphics | pred:alt.atheism)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHYRBdBycfne",
        "colab_type": "code",
        "outputId": "1c98691e-ed93-47e6-8fe8-4dbfde4a9d94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "print(x_test[371])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: kempmp@phoenix.oulu.fi (Petri Pihko)\n",
            "Subject: Re: Consciousness part II - Kev Strikes Back!\n",
            "Organization: University of Oulu, Finland\n",
            "X-Newsreader: TIN [version 1.1 PL9]\n",
            "Lines: 30\n",
            "\n",
            "Scott D. Sauyet (SSAUYET@eagle.wesleyan.edu) wrote:\n",
            "> In <1993Apr21.163848.8099@cs.nott.ac.uk> \n",
            "> Kevin Anthony (kax@cs.nott.ac.uk) writes:\n",
            "\n",
            "> > Firstly, I'm not impressed with the ability of algorithms. They're\n",
            "> > great at solving problems once the method has been worked out, but not\n",
            "> > at working out the method itself.\n",
            ">   [ .. crossword example deleted ... ]\n",
            "\n",
            "> Have you heard of neural networks?  I've read a little about them, and\n",
            "> they seems to overcome most of your objections.\n",
            "\n",
            "I'm sure there are many people who work with neural networks and\n",
            "read this newsgroup. Please tell Kevin what you've achieved, and\n",
            "what you expect.\n",
            "\n",
            "> I am not saying that NNs will solve all such problems, but I think\n",
            "> they show that it is not as hard as you think to come up with\n",
            "> mechanical models of consciousness.\n",
            "\n",
            "Indeed. I think dualism is a non-solution, or, as Dennett recently\n",
            "put it, a dead horse. \n",
            "\n",
            "Petri\n",
            "\n",
            "--\n",
            " ___. .'*''.*        Petri Pihko    kem-pmp@          Mathematics is the Truth.\n",
            "!___.'* '.'*' ' .    Pihatie 15 C    finou.oulu.fi    Physics is the Rule of\n",
            "       ' *' .* '*    SF-90650 OULU  kempmp@           the Game.\n",
            "          *'  *  .*  FINLAND         phoenix.oulu.fi  -> Chemistry is The Game.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUBegwcKcyEG",
        "colab_type": "text"
      },
      "source": [
        "This post talks more about computing than `alt.atheism` (the true category), so our model placed it into the only computing category available to it: `comp.graphics`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcZQ6HbqdMcF",
        "colab_type": "text"
      },
      "source": [
        "## STEP 4: Making Predictions on New Data in Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp8tw3Y0cnJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc=t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZOeu9cDdguM",
        "colab_type": "code",
        "outputId": "87b49a47-ae90-4fe9-c111-3a5e7d7cbe0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictor.predict('Jesus Christ is the central figure of Christianity.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'soc.religion.christian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuMmx8f5dr45",
        "colab_type": "code",
        "outputId": "1e5fb87a-b359-4d40-f8a6-894f4bc5fb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# predicted probability scores for each category\n",
        "predictor.predict_proba('Jesus Christ is the central figure of Christianity.')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.9838422e-03, 5.1028078e-04, 5.2686210e-04, 9.9497896e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldxX1mtLd3Nq",
        "colab_type": "code",
        "outputId": "ce4b0ce1-c326-42d6-c837-53019a9b453a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictor.get_classes()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tHos7V6d8RQ",
        "colab_type": "text"
      },
      "source": [
        "As expected, `soc.religion.christian` is assigned the highest probability.\n",
        "\n",
        "Let's invoke the `explain` method to see which words contribute most to the classification.\n",
        "\n",
        "We will need a forked version of the **eli5** library that supportes TensorFlow Keras, so let's install it first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6HjLF9dd5iZ",
        "colab_type": "code",
        "outputId": "c91dfaf0-9674-445c-8767-3b80bd5dfe9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install -q git+https://github.com/amaiya/eli5@tfkeras_0_10_1\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HgZDLYUeVaM",
        "colab_type": "code",
        "outputId": "766675f6-7ff3-4094-83fc-1086c0baf256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "predictor.explain('Jesus Christ is the central figure in Christianity.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "\n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=soc.religion.christian\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>1.000</b>, score <b>8.984</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +9.242\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.37%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.258\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 67.55%); opacity: 0.95\" title=\"2.589\">jesus</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.98%); opacity: 0.97\" title=\"3.006\">christ</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.99%); opacity: 0.84\" title=\"0.701\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.54%); opacity: 0.81\" title=\"0.203\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.47%); opacity: 0.82\" title=\"0.321\">central</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.15%); opacity: 0.80\" title=\"0.014\">figure</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.99%); opacity: 0.83\" title=\"0.482\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"3.491\">christianity</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcph2bSLe5cW",
        "colab_type": "text"
      },
      "source": [
        "The words in the darkest shade of green contribute most to the classification and agree with what you would expect for this example.\n",
        "\n",
        "We can save and reload our predictor for later deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1nzxI_Jec-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor.save('/tmp/my_distilbert_predictor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDEU2s03fHsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reloaded_predictor = ktrain.load_predictor('/tmp/my_distilbert_predictor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4R1r12rgNlI",
        "colab_type": "code",
        "outputId": "9e53f714-085d-4ea2-93bc-65a204762e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reloaded_predictor.predict('My computer monitor is really blurry.')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'comp.graphics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCJgsiUzg1wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}